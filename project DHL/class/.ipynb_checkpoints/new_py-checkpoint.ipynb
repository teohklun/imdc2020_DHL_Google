{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "#notebook-container {\n",
       "    width: 100%\n",
       "}\n",
       "\n",
       ".code_cell {\n",
       "   flex-direction: row !important;\n",
       "}\n",
       "\n",
       ".code_cell .input {\n",
       "    width: 50%\n",
       "}\n",
       "\n",
       ".code_cell .output_wrapper {\n",
       "    width: 50%\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "        from IPython.core.display import display, HTML\n",
    "        display(HTML(\"\"\"\n",
    "        <style>\n",
    "        #notebook-container {\n",
    "            width: 100%\n",
    "        }\n",
    "\n",
    "        .code_cell {\n",
    "           flex-direction: row !important;\n",
    "        }\n",
    "\n",
    "        .code_cell .input {\n",
    "            width: 50%\n",
    "        }\n",
    "\n",
    "        .code_cell .output_wrapper {\n",
    "            width: 50%\n",
    "        }\n",
    "        </style>\n",
    "        \"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global param, config\n",
    "\n",
    "bucketName = \"real-bucket-dhl\"\n",
    "bucketTempName = \"real-bucket-dhl-temp\"\n",
    "csvPath = \"3.csv\"\n",
    "gStorage = 'gs://real-bucket-dhl/3.csv'\n",
    "optimalCsvName = \"optimalRoutes.csv\"\n",
    "optimalCsvPath = \"files/february/\" + optimalCsvName\n",
    "gStorageOptimalCsv = \"gs://real-bucket-dhl/files/february/\" + optimalCsvName\n",
    "url = 'http://35.213.166.175:3000' #vroomRoute\n",
    "\n",
    "date = \"20200204\"\n",
    "session = \"a\"\n",
    "street = \"Jalan Rumbia, Kampung Seberang Paya, 11900 Bayan Lepas, Pulau Pinang\"\n",
    "\n",
    "defaultZip = 99\n",
    "defaultCapacity = 99999\n",
    "\n",
    "mode = \"noCloud\"\n",
    "morningStart = \"08:45:00\"\n",
    "morningEnd = \"13:59:59\"\n",
    "\n",
    "afternoonStart = \"14:00:00\"\n",
    "afternoonEnd = \"20:00:00\"\n",
    "\n",
    "useZip = False\n",
    "customCapacity = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# import import_ipynb\n",
    "from job import Job\n",
    "from vehicle import Vehicle\n",
    "import importlib\n",
    "import numpy as np \n",
    "from typing import Dict, Tuple, Sequence, List, Any\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import types\n",
    "import requests\n",
    "\n",
    "from typing import Dict, Tuple, Sequence, List, Any\n",
    "# import polyline\n",
    "\n",
    "import json\n",
    "\n",
    "import pprint\n",
    "\n",
    " \n",
    "import os\n",
    "# import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "# when use flask open back\n",
    "# from flask import Flask\n",
    "from io import StringIO\n",
    "# from flask import jsonifyaf\n",
    "\n",
    "\n",
    "# datastore_client = datastore.Client()\n",
    "\n",
    "\n",
    "# import google.cloud.storage as gcs\n",
    "# import webapp2\n",
    "\n",
    "# from google.appengine.api import app_identity\n",
    "#[END imports]\n",
    "\n",
    "#[START retries]\n",
    "# my_default_retry_params = gcs.RetryParams(initial_delay=0.2,\n",
    "#                                           max_delay=5.0,\n",
    "#                                           backoff_factor=2,\n",
    "#                                           max_retry_period=15)\n",
    "# gcs.set_default_retry_params(my_default_retry_params)\n",
    "\n",
    "# CLOUD_STORAGE_BUCKET = os.environ.get('CLOUD_STORAGE_BUCKET')\n",
    "# # Create a Cloud Storage client.\n",
    "# storage_client = gcs.Client()\n",
    "\n",
    "# # Get the bucket that the file will be uploaded to.\n",
    "# bucket = storage_client.get_bucket(CLOUD_STORAGE_BUCKET)\n",
    "\n",
    "# def get(self):\n",
    "#     # bucket_name = os.environ.get('BUCKET_NAME',\n",
    "#     #                              app_identity.get_default_gcs_bucket_name())\n",
    "\n",
    "#     # self.response.headers['Content-Type'] = 'text/plain'\n",
    "#     # self.response.write('Demo GCS Application running from Version: '\n",
    "#     #                     + os.environ['CURRENT_VERSION_ID'] + '\\n')\n",
    "#     # self.response.write('Using bucket name: ' + bucket_name + '\\n\\n')\n",
    "# #[END get_default_bucket]\n",
    "\n",
    "#     # bucket = '/' + bucket_name\n",
    "#     filename = bucket + '/demo-testfile'\n",
    "#     # self.tmp_filenames_to_clean_up = []\n",
    "\n",
    "# def gcloudWriteFile(self, filename, content, optionWrite = \"w\"):\n",
    "#     \"\"\"Create a file.\n",
    "\n",
    "#     The retry_params specified in the open call will override the default\n",
    "#     retry params for this particular file handle.\n",
    "\n",
    "#     Args:\n",
    "#       filename: filename.\n",
    "#     \"\"\"\n",
    "#     self.response.write('Creating file %s\\n' % filename)\n",
    "\n",
    "#     write_retry_params = gcs.RetryParams(backoff_factor=1.1)\n",
    "#     gcs_file = gcs.open(filename,\n",
    "#                         optionWrite,\n",
    "#                         content_type='text/plain',\n",
    "#                         options={'x-goog-meta-foo': 'foo',\n",
    "#                                  'x-goog-meta-bar': 'bar'},\n",
    "#                         retry_params=write_retry_params)\n",
    "#     gcs_file.write(content)\n",
    "#     gcs_file.close()\n",
    "#     # self.tmp_filenames_to_clean_up.append(filename)\n",
    "\n",
    "# def gcloudReadFile(self, filename):\n",
    "#     self.response.write('Abbreviated file content (first line and last 1K):\\n')\n",
    "\n",
    "#     gcs_file = gcs.open(filename)\n",
    "#     self.response.write(gcs_file.read())\n",
    "#     contents = gcs_file.read()\n",
    "#     gcs_file.close()\n",
    "\n",
    "# def write_file(fileName : str, content : str):\n",
    "#     text_file = open(fileName, \"w\")\n",
    "#     n = text_file.write(content )\n",
    "#     text_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# real-bucket-dhl/files/february/day/x/session/fileType\n",
    "def getResponseFileName(date : str, session : str )-> str:\n",
    "#     from pathlib import Path\n",
    "\n",
    "#     path = Path(__file__).parent / \"../data/test.csv\"\n",
    "#     return \"files/february/\" + getDayFromInputDay(str(date)) + \"/input.json\"\n",
    "    return \"files/february/response/\" + str(date) + \"-\" + session + \"-response.json\"\n",
    "\n",
    "def getInputeForResponseFileName(date: str, sesison: str) -> str:\n",
    "    return \"files/february/input/\" + str(date) + \"-\" + session  + \"-input.json\"\n",
    "\n",
    "# def getResponseCsvFilePath(date: str, session : str) -> str:\n",
    "#     return \"files/february/response/day/\" + getDayFromInputDay(str(date))\n",
    "def getDayFromInputDay(date: str) -> str:\n",
    "    return date[-2:]\n",
    "# def saveRecordToDataBase(date : str, session : str) -> str: \n",
    "#     host = os.getenv('MYSQL_HOST')\n",
    "#     port = os.getenv('MYSQL_PORT')\n",
    "#     user = os.getenv('MYSQL_USER')\n",
    "#     password = os.getenv('MYSQL_PASSWORD')\n",
    "#     database = os.getenv('MYSQL_DATABASE')\n",
    "\n",
    "#     json_file_name = getResponseFileName(date, session)\n",
    "#     # json_file_name = \"response.json\"\n",
    "\n",
    "#     conn = pymysql.connect(\n",
    "#         host=host,\n",
    "#         port=int(3306),\n",
    "#         user=\"root\",\n",
    "#         passwd=password,\n",
    "#         db=\"dhl-project\",)\n",
    "#     #     charset='utf8mb4')\n",
    "#     try:\n",
    "#         connObject = conn.cursor()\n",
    "#         command = \"INSERT INTO optimal_summary (date, session, response_name) VALUES (%s,%s,%s)\"\n",
    "\n",
    "#         connObject.execute(command, (date,session,json_file_name,))\n",
    "#         # print(df)\n",
    "#         conn.commit()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(\"Exeception occured:{}\".format(e))\n",
    "\n",
    "#     finally:\n",
    "#         conn.close()\n",
    "#         return json_file_name\n",
    "    \n",
    "# def deleteRecordToDataBase(date : str, session : str): \n",
    "#     host = os.getenv('MYSQL_HOST')\n",
    "#     port = os.getenv('MYSQL_PORT')\n",
    "#     user = os.getenv('MYSQL_USER')\n",
    "#     password = os.getenv('MYSQL_PASSWORD')\n",
    "#     database = os.getenv('MYSQL_DATABASE')\n",
    "#     # json_file_name = \"response.json\"\n",
    "\n",
    "#     conn = pymysql.connect(\n",
    "#         host=host,\n",
    "#         port=int(3306),\n",
    "#         user=\"root\",\n",
    "#         passwd=password,\n",
    "#         db=\"dhl-project\",)\n",
    "#     #     charset='utf8mb4')\n",
    "#     try:\n",
    "#         connObject = conn.cursor()\n",
    "#         command = \"delete from optimal_summary where date = %s and session = %s\"\n",
    "#         connObject.execute(command, (date,session))\n",
    "#         # print(df)\n",
    "#         conn.commit()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(\"Exeception occured:{}\".format(e))\n",
    "\n",
    "#     finally:\n",
    "#         conn.close()\n",
    "\n",
    "def write_file(fileName : str, content : str):\n",
    "\n",
    "    text_file = open(fileName, \"w\")\n",
    "    n = text_file.write(content )\n",
    "    text_file.close()\n",
    "    \n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "    \n",
    "# def getTimeWindow(start, end):\n",
    "    \n",
    "def getMiliSec(time_str: float) -> int:\n",
    "    \"\"\"Get Seconds from time.\"\"\"\n",
    "#     if(type(time_str) == \"float\"):\n",
    "#     if(type(time_str) is types.Float):\n",
    "#             elif isinstance(obj, np.floating):\n",
    "\n",
    "    time_str = str(time_str)\n",
    "    if(len(time_str.split(':')) ==3  ):\n",
    "        h, m,s = time_str.split(':')\n",
    "    else:\n",
    "        print(len(time_str.split(':')))\n",
    "        print(time_str)\n",
    "        h, m = time_str.split(':')\n",
    "        s= \"00\"\n",
    "    \n",
    "    return int(h) * 3600   + int(m) * 60 + int(s)\n",
    "\n",
    "def getTimeWindow(start : float ,end : float) -> List:\n",
    "    if(start != start ):\n",
    "        start = \"00:00:00\"\n",
    "#     if(end == \"23:59\"):\n",
    "#         end = \"20:00\"\n",
    "    if(end != end):\n",
    "        end = \"23:59:00\"\n",
    "    return [ getMiliSec(start), getMiliSec(end) ]\n",
    "\n",
    "def getTime24hour(seconds : int):\n",
    "    import datetime\n",
    "    return str(datetime.timedelta(seconds=seconds))\n",
    "    \n",
    "def sendRequest(fileName : str):\n",
    "\n",
    "    #payload = open(\"request.json\")\n",
    "    headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    r = requests.post(url, data=open(fileName, 'rb'), headers=headers) \n",
    "\n",
    "#function declaration\n",
    "def getActualQueryAdress(companyName: str, street : str)-> str:\n",
    "    string = companyName + \"+\" + street\n",
    "    return string\n",
    "\n",
    "def parseStringToHtml(string :str) -> str:\n",
    "    string  =string.replace(\" \",\"+\")\n",
    "    return string\n",
    "\n",
    "def getLocationWithStreetNameOrCustomerName(companyName: str, street : str) -> List:\n",
    "    stringRquestStreet = getActualQueryAdress(parseStringToHtml(companyName), parseStringToHtml(street))\n",
    "    api_key = \"AIzaSyA2H1uflVbzM7wtGeMlbwpLKnMkFIJdWVc\"\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json?address=' + stringRquestStreet + ',+CA&key='+api_key+''\n",
    "    # url = \"https://maps.googleapis.com/maps/api/js?key=\"+api_key+\"&libraries=places\"\n",
    "    # url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=\"+stringRquestStreet+\"&inputtype=textquery&fields=formatted_address,name,plus_code,geometry&key=\"+api_key+\"\"\n",
    "    # url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=BJ Court&inputtype=textquery&fields=formatted_address,name,plus_code,geometry&key=\"+api_key+\"\"\n",
    "\n",
    "    payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "\n",
    "    # POST with JSON \n",
    "    r = requests.post(url, data=json.dumps(payload))\n",
    "\n",
    "    # Response, status etc\n",
    "    r.text\n",
    "    parsed = json.loads(r.text)\n",
    "\n",
    "    return parsed[\"results\"][0][\"geometry\"][\"location\"]\n",
    "\n",
    "def getDeliveryRoute(partialDataFrame : List, fullDataFrame : List, session : str):\n",
    "#     print(\"DASDASDDASDSDSDASDS\")\n",
    "    deliveryList = []\n",
    "    deliveryListRoute=[]\n",
    "    \n",
    "    arraySearched = []\n",
    "#     print(len(partialDataFrame))\n",
    "#     for x in range(0, len(partialDataFrame)):\n",
    "    for index, x in partialDataFrame.iterrows():\n",
    "        valid = False\n",
    "        if(x[\"Act Ckpt Code\"] ==  \"DEPAR\" or x[\"Act Ckpt Code\"]==  \"ARRVD\"):\n",
    "#             valid = True\n",
    "            \n",
    "            if(x[\"Act Ckpt Code\"] == \"DEPAR\"):\n",
    "            \n",
    "                subFrame = partialDataFrame.loc[partialDataFrame[\"Courier id\"] == x[\"Courier id\"]]\n",
    "                subFrame.reset_index(inplace=True)\n",
    "                arraySearched.append(x[\"Courier id\"])\n",
    "\n",
    "                countArraySearched = arraySearched.count(x[\"Courier id\"])\n",
    "                departTime = None\n",
    "                arrivalTime = None\n",
    "                counterLoop = 0\n",
    "                indexFirst = subFrame.index[0]\n",
    "                for index2, k in subFrame.iterrows():\n",
    "                    if(counterLoop < countArraySearched):\n",
    "                        if(k[\"Act Ckpt Code\"] == \"DEPAR\"):\n",
    "                            if(index2 != indexFirst):\n",
    "                                if(subFrame.iloc[index2-1][\"Act Ckpt Code\"] != \"ARRVD\"):\n",
    "                                    arrivalTime = None\n",
    "                                    departTime = getMiliSec(k[\"Act Tm\"])\n",
    "                            else:\n",
    "                                departTime = getMiliSec(k[\"Act Tm\"])\n",
    "\n",
    "                        if(k[\"Act Ckpt Code\"] == \"ARRVD\"):\n",
    "                            arrivalTime = getMiliSec(k[\"Act Tm\"])\n",
    "                            counterLoop+=1\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                if(session == \"m\"):\n",
    "                    if(arrivalTime != None):\n",
    "                        if( (departTime > getMiliSec(morningStart))  | ( arrivalTime > getMiliSec(morningEnd) ) ):\n",
    "                            valid = True\n",
    "                    elif((departTime > getMiliSec(morningStart)) & (departTime < getMiliSec(afternoonStart) ) ):\n",
    "                            valid = True\n",
    "                    else:\n",
    "                        valid = False\n",
    "                        print(\"unknow prepare sitaution 5\")\n",
    "                elif(session ==\"a\"):\n",
    "                    if(arrivalTime != None):\n",
    "                        if( (departTime > getMiliSec(afternoonStart))  | ( arrivalTime < getMiliSec(afternoonEnd) )):\n",
    "                            valid = True\n",
    "                    elif(departTime > getMiliSec(afternoonStart) ):\n",
    "                        valid = True\n",
    "                    else:\n",
    "                        valid = False\n",
    "                        print(\"unknow prepare sitaution 6\")\n",
    "                else:\n",
    "                    print(\"session error\")\n",
    "            \n",
    "            if(deliveryListRoute != []):\n",
    "                deliveryList.append(deliveryListRoute)\n",
    "                deliveryListRoute = []\n",
    "            else:\n",
    "                deliveryListRoute = []\n",
    "        else:\n",
    "#             if(valid):\n",
    "            #logic for morning afternoon\n",
    "            if( (session == \"m\") & (getMiliSec(x[\"Act Tm\"]) > getMiliSec(morningStart) ) & (getMiliSec(x[\"Act Tm\"]) < getMiliSec(morningEnd) ) ):\n",
    "                valid = True\n",
    "            elif( (session == \"a\") & (getMiliSec(x[\"Act Tm\"]) > getMiliSec(afternoonStart) ) & (getMiliSec(x[\"Act Tm\"]) < getMiliSec(afternoonEnd)  ) ) :\n",
    "                valid = True\n",
    "            else: #false for afternoon session first\n",
    "                valid = False\n",
    "            if(valid):\n",
    "                if(x[\"lgtd\"] != x[\"lgtd\"] or x[\"lat\"] != x[\"lat\"]): # lat or long None\n",
    "                    \n",
    "                    if(mode == \"noCloud\"):\n",
    "                        print(\"trigger no cloud geocode . . .\")\n",
    "                        lat = 2.7047421\n",
    "                        lgtd = 101.9168708\n",
    "                    else:\n",
    "                        location = getLocationWithStreetNameOrCustomerName(x[\"Customer Name\"], x[\"Street\"])\n",
    "\n",
    "                        lat = location[\"lat\"]\n",
    "                        lgtd = location[\"lng\"]\n",
    "        #                     print(lat)\n",
    "                        #update the file\n",
    "                        fullDataFrame.at[index, 'lat'] = lat\n",
    "                        fullDataFrame.at[index, 'lgtd'] = lgtd\n",
    "                    #update today\n",
    "                    x[\"lat\"] = lat\n",
    "                    x[\"lgtd\"] = lgtd\n",
    "        if(valid):\n",
    "            deliveryListRoute.append(x)\n",
    "#     print(deliveryList[0])\n",
    "    return deliveryList, fullDataFrame\n",
    "\n",
    "def getSessionWithTimeWindowMSec(start : int, end : int):\n",
    "    timeWindowM = getTimeWindow(morningStart,  morningEnd )\n",
    "    timeWindowA = getTimeWindow(afternoonStart,  afternoonEnd )\n",
    "    if(start >= timeWindowM[0] and end <= timeWindowM[1]):\n",
    "        session = \"m\"\n",
    "    elif(start >= timeWindowA[0] and end <= timeWindowA[1]):\n",
    "        session = \"a\"\n",
    "    else:\n",
    "        session = \"asdas\"\n",
    "    return session\n",
    "\n",
    "def getSessionWithTimeWindow(start: str, end: str) -> str:\n",
    "    start, end = getTimeWindow(start, end)\n",
    "    timeWindowM = getTimeWindow(morningStart,  morningEnd )\n",
    "    timeWindowA = getTimeWindow(afternoonStart,  afternoonEnd )\n",
    "    if(start >= timeWindowM[0] and end <= timeWindowM[1]):\n",
    "        session = \"m\"\n",
    "    elif(start >= timeWindowA[0] and end <= timeWindowA[1]):\n",
    "        session = \"a\"\n",
    "    else:\n",
    "        session = \"asdas\"\n",
    "    return session\n",
    "\n",
    "    \n",
    "def getTimeWindowWithSession(session : str) -> List:\n",
    "    if(session == \"m\"):\n",
    "#         timeWindow = getTimeWindow(\"09:00\",  \"18:45\" )\n",
    "#         timeWindow = getTimeWindow(\"09:00\",  \"13:45\" )\n",
    "        timeWindow = getTimeWindow(morningStart,  morningEnd )\n",
    "\n",
    "    elif(session ==\"a\"):\n",
    "        timeWindow = getTimeWindow(afternoonStart,  afternoonEnd )\n",
    "#         timeWindow = getTimeWindow(\"09:00\",  \"18:45\" )\n",
    "\n",
    "    else:\n",
    "        print(\"undefined session\")\n",
    "        timeWindow = getTimeWindow(\"09:00:00\",  \"13:00:00\" ) #default morning\n",
    "        \n",
    "    return timeWindow\n",
    "    \n",
    "def isNotNull(var):\n",
    "    return var == var\n",
    "def createJobsAndVehiclesList(deliveryList : List, timeWindow : List, zipSet :List):\n",
    "    subangLocation = [101.9381 ,2.7297] #should be seremban\n",
    "    jobList = []\n",
    "    vehicleList = []\n",
    "#     counter = 1\n",
    "#     counter2 = 1\n",
    "    deliveryOrPick = [1]\n",
    "    duration = 300\n",
    "#     print(deliveryList)\n",
    "    for x in deliveryList:\n",
    "        for y in x:\n",
    "#             print(y[\"Act Ckpt Code\"])\n",
    "#             if(y[\"Act Ckpt Code\"] == \"ARRVD\" or  y[\"Act Ckpt Code\"] == \"DEPAR\"):\n",
    "            if(y[\"Act Ckpt Code\"]  == \"DEPAR\"): #just need to add one vehicle\n",
    "                if(useZip):\n",
    "                    vehicleList.append(Vehicle(y[\"id\"],subangLocation, defaultCapacity, list(zipSet[y[\"Courier id\"]]) + [defaultZip] , timeWindow, subangLocation, y[\"Courier id\"]))\n",
    "                else:\n",
    "                    vehicleList.append(Vehicle(y[\"id\"],subangLocation, defaultCapacity, [] , timeWindow, subangLocation, y[\"Courier id\"]))\n",
    "\n",
    "            #                 counter2+=1\n",
    "            else:\n",
    "                if(y[\"Act Ckpt Code\"]  != \"ARRVD\"): \n",
    "    #                 print(y)\n",
    "    #because the history actual time sometimes just does not fit in the range, so it will only be useful for new input\n",
    "    # getTimeWindow(y[\"Open\"], y[\"Closed\"])\n",
    "                    if(useZip):\n",
    "                        jobList.append(Job(y[\"id\"],deliveryOrPick,[y[\"lgtd\"], y[\"lat\"]] , [int(y[\"zip\"])] if y[\"zip\"] == y[\"zip\"] else [defaultZip], [timeWindow], duration , y[\"Street\"]  if y[\"Street\"] == y[\"Street\"] else \"street is blank\"        ))\n",
    "                    else:\n",
    "                        jobList.append(Job(y[\"id\"],deliveryOrPick,[y[\"lgtd\"], y[\"lat\"]] , [], [timeWindow], duration , y[\"Street\"]  if y[\"Street\"] == y[\"Street\"] else \"street is blank\"        ))\n",
    "    #                 counter+=\n",
    "    return jobList, vehicleList\n",
    "\n",
    "def createDictionaryObjectJobsVehicles(jobsList : List,vehicleList : List) -> dict:\n",
    "    dict_t = {}\n",
    "    dict_t[\"jobs\"] = []\n",
    "    jobCounter = 0\n",
    "    for x in jobsList:\n",
    "        dict_t[\"jobs\"].append(x.__dict__)\n",
    "        jobCounter = jobCounter + 1\n",
    "\n",
    "    dict_t[\"vehicles\"] = []\n",
    "    capacity = [  int (round(jobCounter/ len(vehicleList)) * 120 / 100 ) ]\n",
    "    print(\"capacity : \"  + str(capacity))\n",
    "    for y in vehicleList:\n",
    "        if(customCapacity):\n",
    "#         y.capacity = [ round(jobCounter/ len(vehicleList)) + 1]\n",
    "            y.capacity = capacity\n",
    "#         y.capacity = [ round(jobCounter/ len(vehicleList))]\n",
    "\n",
    "        #test.append(json.dumps(x.__dict__))\n",
    "        dict_t[\"vehicles\"].append(y.__dict__)\n",
    "    return dict_t\n",
    "\n",
    "# Function to insert row in the dataframe \n",
    "def addRowToDataFrame(row_number, df, row_value): \n",
    "    # Slice the upper half of the dataframe \n",
    "    df1 = df[0:row_number] \n",
    "   \n",
    "    # Store the result of lower half of the dataframe \n",
    "    df2 = df[row_number:] \n",
    "   \n",
    "    # Inser the row in the upper half dataframe \n",
    "    df1.loc[row_number]=row_value \n",
    "   \n",
    "    # Concat the two dataframes \n",
    "    df_result = pd.concat([df1, df2]) \n",
    "   \n",
    "    # Reassign the index labels \n",
    "    df_result.index = [*range(df_result.shape[0])] \n",
    "   \n",
    "    # Return the updated dataframe \n",
    "    return df_result \n",
    "\n",
    "def addJob(dataFrame,date,session ,street, actBase = \"P\", openend = \"00:00:00\", closed = \"23:59:00\"):\n",
    "    from numpy import nan as Nan\n",
    "\n",
    "    actDt = int(date)\n",
    "    street = street\n",
    "    \n",
    "#     if(openend == None):\n",
    "#         openend = \"00:00\"\n",
    "#     if(closed == None):\n",
    "#         closed = \"00:00\"\n",
    "        \n",
    "    dateArrival = date\n",
    "    pickUpType = \"REGULAR\"\n",
    "    deliveryType = \"NORMAL\"\n",
    "    \n",
    "    name = \"name\"\n",
    "    \n",
    "    pudSvcArea = \"KUL\"\n",
    "    pudType = \"pudType\"\n",
    "    actCkpyCode = \"OK\"\n",
    "    id = len(dataFrame) + 1\n",
    "    awbBooking = session + \"_\" + str(id)\n",
    "    closed = closed\n",
    "    openend = openend\n",
    "    \n",
    "    \n",
    "    if(session == \"m\"):\n",
    "        actTm = \"09:01:00\"\n",
    "    else:\n",
    "        actTm = \"15:00:00\"\n",
    "    \n",
    "    dateArrival = dateArrival\n",
    "    weight = 0\n",
    "    tPcs = 0\n",
    "    parcelPcs = 0\n",
    "    shpCnt = 0\n",
    "    palletPcs = 0\n",
    "    parcelP = 0\n",
    "    proCode = \"test\"\n",
    "    prodGrp = \"testG\"\n",
    "    pickUpType = pickUpType\n",
    "    actBase = actBase\n",
    "    city = \"123\"\n",
    "    zip = \"11111\"\n",
    "    street = street\n",
    "    customerName = name\n",
    "    if(dataFrame.all != dataFrame.all):\n",
    "        print(\"dataFrame is blank array\")\n",
    "    courierID = dataFrame.iloc[0][\"Courier id\"]\n",
    "    pudCycle = \"B\"\n",
    "    pudEac = \"EAC\"\n",
    "#     actDt = None\n",
    "\n",
    "    new = pd.DataFrame({'PUD Svc Area': [pudSvcArea], \n",
    "                     'PUD Fac': [pudEac],\n",
    "                     'PUD Cycle': [pudCycle],\n",
    "                      'Courier id':courierID,\n",
    "                      'Courier Type':  np.nan,\n",
    "                      'Customer Name': [customerName],\n",
    "                      'Street': [street],\n",
    "                      'zip': [zip],\n",
    "                      'City': [city],\n",
    "                      'Act Dt': actDt,\n",
    "                      'Act Base': [actBase],\n",
    "                      'Delivery Type': [deliveryType],\n",
    "                      'Pickup Type': [pickUpType],\n",
    "                      'Prod Grp': [prodGrp],\n",
    "                      'Prod Code': [proCode],\n",
    "                      'ShpCnt': [shpCnt],\n",
    "                      'Pallets Pcs': [palletPcs],\n",
    "                      'Parcel Pcs': [parcelP],\n",
    "                      'Total Pcs': [tPcs],\n",
    "                      'Weight': [weight],\n",
    "                      'AR dtm': [dateArrival],\n",
    "                      'Act Tm': [actTm],\n",
    "                      'Open': [openend],\n",
    "                      'Closed': [closed],\n",
    "                      'lat':  pd.Series([np.nan]),\n",
    "                      'lgtd':  pd.Series([np.nan]),\n",
    "                      'awb_booking': [awbBooking],\n",
    "                      'Act Ckpt Code': [actCkpyCode],\n",
    "                      'PuD Type': [pudType],\n",
    "                      'Stop Code':  pd.Series([np.nan]),\n",
    "                        'id' : [id],\n",
    "                    'MarkerColor':  pd.Series([np.nan]), })\n",
    "    \n",
    "#     print(new.iloc[0][\"Act Dt\"])\n",
    "    \n",
    "    partialDataFrame = dataFrame.loc[(dataFrame['Courier id'] == courierID) & (dataFrame[\"Act Dt\"] == int(date)) & (dataFrame[\"Act Ckpt Code\"] == \"DEPAR\")]\n",
    "    \n",
    "#     print(partialDataFrame.index)\n",
    "#     print(type(new.iloc[0][\"Open\"]))\n",
    "    dataFrame = addRowToDataFrame(partialDataFrame.index[0] + 1, dataFrame, new.iloc[0])\n",
    "#     dataFrame = dataFrame.append(new, ignore_index=True)\n",
    "    \n",
    "    return dataFrame,awbBooking\n",
    "\n",
    "def gotUnssigned(dict_t : dict) -> str:\n",
    "    if(dict_t != None and (dict_t[\"code\"] != 0) ):\n",
    "        return(dict_t[\"error\"])\n",
    "    else:\n",
    "        return dict_t[\"unassigned\"]\n",
    "\n",
    "    \n",
    "def routeWithDateAndSession(date : str,  session: str, street: None):\n",
    "\n",
    "    # fullDataFrame = pd.read_csv(\"3.csv\")\n",
    "    fullDataFrame = pd.read_csv(csvPath)\n",
    "\n",
    "    \n",
    "    if(~(street != street)):\n",
    "        fullDataFrame, newAwbBooking = addJob(fullDataFrame, date, session ,street)\n",
    "    \n",
    "    fullDataFrame = fullDataFrame.loc[(fullDataFrame['Courier Type'] != \"NON_GCA5\") ]\n",
    "    partialDataFrame = fullDataFrame\n",
    "\n",
    "    partialDataFrame = partialDataFrame.loc[partialDataFrame['Act Dt'] == int(date)]\n",
    "#     partialDataFrame = partialDataFrame.sort_values('Courier id')\n",
    "    #     fullDataFrame\n",
    "    deliveryListRoute, fullDataFrame = getDeliveryRoute(partialDataFrame, fullDataFrame)\n",
    "#     print(deliveryListRoute)\n",
    "    jobsList, vehicleList = createJobsAndVehiclesList(deliveryListRoute, getTimeWindowWithSession(session))\n",
    "    dict_t = createDictionaryObjectJobsVehicles(jobsList,vehicleList )\n",
    "\n",
    "#     pprint.pprint(dict_t)\n",
    "    content = json.dumps(dict_t, cls=NpEncoder) \n",
    "#     write_file(\"content.json\", content)\n",
    "\n",
    "    headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    r = requests.post(url, data=open(\"content.json\", 'rb'), headers=headers)    \n",
    "    \n",
    "    #record the response to file\n",
    "    # json_file_name = saveRecordToDataBase(date, session)\n",
    "    # deleteRecordToDataBase(date, session)\n",
    "#     write_file(json_file_name, r.content)\n",
    "\n",
    "\n",
    "    text_file = open(json_file_name, \"wb\")\n",
    "    n = text_file.write(r.content )\n",
    "    text_file.close()\n",
    "    \n",
    "#     #update the added job to csv\n",
    "    fullDataFrame.to_csv(csvPath, index=False)\n",
    "    \n",
    "#     print(len(fullDataFrame))\n",
    "#     print(partialDataFrame)\n",
    "    return r\n",
    "\n",
    "# r =routeWithDateAndSession(date, session, \"Jalan Rumbia, Kampung Seberang Paya, 11900 Bayan Lepas, Pulau Pinang\")\n",
    "\n",
    "def getRouteIndexWithID(readed : dict, jobID :id)-> dict:\n",
    "    for indexRoute, routes in enumerate( readed[\"routes\"] , start = 0): \n",
    "        for indexStep, step in enumerate( routes[\"steps\"], start = 1):\n",
    "                if(step[\"type\"] == \"job\"):\n",
    "                    if(step[\"job\"] == jobID):\n",
    "                        return indexStep, indexRoute\n",
    "    \n",
    "    return [],[]\n",
    "#     return 1,2,indexRoute\n",
    "\n",
    "def getLocationsAscendingFromRoute(routes : dict, index :int):\n",
    "    locations = []\n",
    "    for step in routes[\"steps\"]:\n",
    "        locations.append(step[\"location\"])\n",
    "    return locations\n",
    "\n",
    "def getRouteDetailWithIDk(ID):\n",
    "    readed = getResponseFileAsDict()    \n",
    "    indexStep, indexRoute = getRouteIndexWithID(readed, ID)\n",
    "    if(indexStep == [] or indexRoute == []) :\n",
    "        return [],[],[]\n",
    "    else:\n",
    "        locations = getLocationsAscendingFromRoute(readed[\"routes\"][indexRoute], indexStep)\n",
    "        idLocation = locations[indexStep]\n",
    "        vehicleID = getRouteVehicleID(readed[\"routes\"], indexRoute)\n",
    "\n",
    "        return readed[\"routes\"][indexRoute], indexStep, vehicleID\n",
    "\n",
    "def getRouteVehicleID(routes, index):\n",
    "    return routes[index][\"vehicle\"]\n",
    "\n",
    "def tryGotUnassignedInResponse(date : str,  session: str, street: None, unassignedJob =None ):\n",
    "\n",
    "    fullDataFrame = pd.read_csv(csvPath)\n",
    "    if(~(street != street)):\n",
    "        fullDataFrame, newAwbBooking = addJob(fullDataFrame, date, session, street)\n",
    "    \n",
    "    fullDataFrame = fullDataFrame.loc[(fullDataFrame['Courier Type'] != \"NON_GCA5\") ]\n",
    "    partialDataFrame = fullDataFrame\n",
    "    partialDataFrame = partialDataFrame.loc[partialDataFrame['Act Dt'] == int(date)]\n",
    "\n",
    "    deliveryListRoute, fullDataFrame = getDeliveryRoute(partialDataFrame, fullDataFrame, session)\n",
    "    jobsList, vehicleList = createJobsAndVehiclesList(deliveryListRoute, getTimeWindowWithSession(session))\n",
    "    \n",
    "    dict_t = createDictionaryObjectJobsVehicles(jobsList,vehicleList )\n",
    "    print(len(deliveryListRoute))\n",
    "    content = json.dumps(dict_t, cls=NpEncoder) \n",
    "    # write_file(\"tmp/content.json\", content)\n",
    "\n",
    "    gcloudWriteFile(\"content.json\", content, \"w\")\n",
    "\n",
    "    data = gcloudReadFile(filename)\n",
    "\n",
    "    headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    # r = requests.post(url, data=open(\"tmp/content.json\", 'rb'), headers=headers)    \n",
    "    r = requests.post(url, data=open(data, 'rb'), headers=headers)    \n",
    "    \n",
    "    # text_file = open(getResponseFileName(date, session), \"wb\")\n",
    "    # n = text_file.write(r.content )\n",
    "    # text_file.close()\n",
    "    gcloudWriteFile(getResponseFileName(date, session), r.content, \"wb\")\n",
    "\n",
    "def getResponseFileAsDict():\n",
    "    import ndjson\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "    blob = bucket.get_blob(getResponseFileName(date,session))\n",
    "    json_data_bytes = blob.download_as_string()\n",
    "    dict_t = json.loads(json_data_bytes)\n",
    "    return dict_t\n",
    "\n",
    "def checkGFileExists(fileName : str, bucketName = bucketName) -> bool:\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "#     name = 'files/february/optimalRoutes.csv'\n",
    "#     name = \"files/february/response/20200204-a-447-response.json\"\n",
    "    return storage.Blob(bucket=bucket, name=fileName).exists(client)\n",
    "\n",
    "def handleOptimalRoute(dataFrame, columns):\n",
    "    from datetime import datetime\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "    gStorageOptimalCsv = 'gs://real-bucket-dhl/files/february/optimalRoutes.csv'\n",
    "    csvFilePathName = 'files/february/optimalRoutes.csv'\n",
    "    historyFilePath = 'files/february/removed/'\n",
    "\n",
    "#     csv = \n",
    "#     string = fullDataFrame.to_csv(None, index=False)\n",
    "    \n",
    "    if (not checkGFileExists(csvFilePathName)):\n",
    "        string = dataFrame.to_csv(None, index=False)\n",
    "        blob = bucket.blob(csvFilePathName)\n",
    "        blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "        print(\"create new optimal route csv\")\n",
    "#     create new csv\n",
    "    else:\n",
    "        print(\"update optimal route csv\")\n",
    "        oldDataFrame = pd.read_csv(gStorageOptimalCsv)\n",
    "        #check this partial inside this csv\n",
    "        batchID = dataFrame.iloc[0][\"batchID\"]\n",
    "        foundPartialDataFrame = oldDataFrame.loc[oldDataFrame[\"batchID\"] == batchID]\n",
    "        \n",
    "        if(not foundPartialDataFrame.empty):\n",
    "            string = foundPartialDataFrame.to_csv(None, index=False)\n",
    "            #store this to change data to history\n",
    "            date_time = datetime.now().strftime(\"%m_%d_%Y, %H:%M:%S\")\n",
    "            blob = bucket.blob(historyFilePath + date_time + \"--\" +str(batchID) +\".csv\" )\n",
    "            blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "        \n",
    "        #update the csv\n",
    "            oldDataFrame = oldDataFrame.drop(oldDataFrame.index[foundPartialDataFrame.index.to_list()])\n",
    "#             oldDataFrame = oldDataFrame.drop(oldDataFrame.index[foundPartialDataFrame.index.to_list()])\n",
    "        \n",
    "        \n",
    "        newDataFrame = pd.concat([oldDataFrame,dataFrame])\n",
    "        newDataFrame.reset_index()\n",
    "        string = newDataFrame.to_csv(None, index=False, columns = columns)\n",
    "        blob = bucket.blob(csvFilePathName)\n",
    "        blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "\n",
    "def getSingleRouteFromRoutes(routes : dict) -> dict:\n",
    "    singleRoute = routes.copy()\n",
    "    singleRoute[\"routes\"] = [routes[\"routes\"][0]]\n",
    "    singleRoute[\"summary\"][\"distance\"] = routes[\"routes\"][0][\"distance\"]\n",
    "    singleRoute[\"summary\"][\"duration\"] = routes[\"routes\"][0][\"duration\"]\n",
    "    singleRoute[\"summary\"][\"service\"] = routes[\"routes\"][0][\"service\"]\n",
    "    singleRoute[\"summary\"][\"cost\"] = routes[\"routes\"][0][\"cost\"]\n",
    "    singleRoute[\"summary\"][\"delivery\"] = [routes[\"routes\"][0][\"delivery\"]]\n",
    "    singleRoute[\"summary\"][\"amount\"] = [routes[\"routes\"][0][\"amount\"]]\n",
    "    return singleRoute\n",
    "        \n",
    "def processRoutedResponse(fullDataFrame, dict_t, session):\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "    for routes in dict_t[\"routes\"]:\n",
    "        df = pd.DataFrame()\n",
    "        vehicleInformation = fullDataFrame.loc[fullDataFrame['id'] == routes[\"vehicle\"]].iloc[0]\n",
    "#         vehicleInformation = fullDataFrame.loc[fullDataFrame['id'] == routes[\"vehicle\"]]\n",
    "        actCkptCode = vehicleInformation[\"Act Ckpt Code\"]\n",
    "#         actCkptCode = vehicleInformation[\"Act Ckpt Code\"].values[0]\n",
    "        vehicleInformation['id'] = vehicleInformation['id'].astype(\"int\")\n",
    "        vehicleInformation['id'] = vehicleInformation['id'].astype(\"str\")\n",
    "        vehicleID = vehicleInformation['id']\n",
    "\n",
    "        date = int(vehicleInformation[\"Act Dt\"])\n",
    "        name = vehicleInformation[\"Courier id\"]\n",
    "        routes[\"steps\"][0][\"name\"] = vehicleInformation[\"Courier id\"]\n",
    "        singleRoute = getSingleRouteFromRoutes(dict_t)\n",
    "\n",
    "        content = json.dumps(singleRoute, cls=NpEncoder) \n",
    "        blob = bucket.blob(\"files/february/response/\"+ str(date) +  \"-\" + session  + \"-\" + vehicleID + \"-response.json\")\n",
    "        blob.upload_from_string(content, \"application/json\")\n",
    "        print(\"created json file\")\n",
    "        \n",
    "        for indexStep, step in enumerate( routes[\"steps\"], start = 1):\n",
    "            if(step[\"type\"] == \"start\" or step[\"type\"] == \"end\"):\n",
    "                startingInformation = vehicleInformation.copy()\n",
    "                startingInformation[\"Act Tm\"] = getTime24hour(step[\"arrival\"])\n",
    "                startingInformation[\"batchID\"] = str(date) +  \"-\" + session  + \"-\" + str(vehicleID)\n",
    "                startingInformation[\"id\"] = str(startingInformation[\"id\"])\n",
    "\n",
    "                if(step[\"type\"] == \"end\"):\n",
    "    #                 startingInformation.at[startingInformation.index[0], \"id\"] = str(startingInformation[\"id\"].values[0]) + \"arrvd\"\n",
    "#                     startingInformation.at[startingInformation.index[0], \"Act Ckpt Code\"] = \"ARRVD\"\n",
    "                    startingInformation[\"Act Ckpt Code\"] = \"ARRVD\"\n",
    "                elif(step[\"type\"] == \"start\"):\n",
    "                     startingInformation[\"Act Ckpt Code\"] = \"DEPAR\"\n",
    "                else:\n",
    "                    print(\"unprepare situation 3\")\n",
    "                    print(\"actCkptCode : \" + actCkptCode)\n",
    "                df = df.append(startingInformation)\n",
    "            elif(step[\"type\"] == \"job\"):\n",
    "                jobInformation = fullDataFrame.loc[fullDataFrame['id'] == int(step[\"job\"])]\n",
    "                if(jobInformation[\"Street\"].values[0] == jobInformation[\"Street\"].values[0]):\n",
    "                    string = jobInformation[\"Street\"].values[0]\n",
    "                    description = re.sub('\\s+', ' ', string)\n",
    "                    step[\"description\"] = description\n",
    "\n",
    "                else:\n",
    "                    step[\"description\"] = \"Street is blank\"\n",
    "                new = pd.DataFrame({'PUD Svc Area': [vehicleInformation[\"PUD Svc Area\"]], \n",
    "                         'PUD Fac': [vehicleInformation[\"PUD Fac\"]],\n",
    "                         'PUD Rte': [vehicleInformation[\"PUD Rte\"]],          \n",
    "                         'PUD Cycle': [vehicleInformation[\"PUD Cycle\"]],\n",
    "                          'Courier id':[vehicleInformation[\"Courier id\"]],\n",
    "                          'Courier Type':  [vehicleInformation[\"Courier Type\"]],\n",
    "                          'Customer Name': [jobInformation[\"Customer Name\"].values[0]],\n",
    "                          'Street': [jobInformation[\"Street\"].values[0]],\n",
    "                          'zip': [jobInformation[\"zip\"].values[0]],\n",
    "                          'City': [jobInformation[\"City\"].values[0]],\n",
    "                          'Act Dt': [jobInformation[\"Act Dt\"].values[0]],\n",
    "                          'Act Base': [jobInformation[\"Act Base\"].values[0]],\n",
    "                          'Delivery Type': [jobInformation[\"Delivery Type\"].values[0]],\n",
    "                          'Pickup Type': [jobInformation[\"Pickup Type\"].values[0]],\n",
    "                          'Prod Grp': [jobInformation[\"Prod Grp\"].values[0]],\n",
    "                          'Prod Code': [jobInformation[\"Prod Code\"].values[0]],\n",
    "                          'ShpCnt': [jobInformation[\"ShpCnt\"].values[0]],\n",
    "                          'Pallets Pcs': [jobInformation[\"Pallets Pcs\"].values[0]],\n",
    "                          'Parcel Pcs': [jobInformation[\"Parcel Pcs\"].values[0]],\n",
    "                          'Total Pcs': [jobInformation[\"Total Pcs\"].values[0]],\n",
    "                          'Weight': [jobInformation[\"Weight\"].values[0]],\n",
    "                          'AR dtm': [jobInformation[\"AR dtm\"].values[0]],\n",
    "                          'Act Tm': [getTime24hour(step[\"arrival\"])],\n",
    "                          'Open': [jobInformation[\"Open\"].values[0]],\n",
    "                          'Closed': [jobInformation[\"Closed\"].values[0]],\n",
    "                          'lat':  [step[\"location\"][1]],\n",
    "                          'lgtd':  [step[\"location\"][0]],\n",
    "                          'awb_booking': [jobInformation[\"awb_booking\"].values[0]],\n",
    "                          'Act Ckpt Code': [jobInformation[\"Act Ckpt Code\"].values[0]],\n",
    "                          'PuD Type': [jobInformation[\"PuD Type\"].values[0]],\n",
    "                          'Stop Code':  [jobInformation[\"Stop Code\"].values[0]],\n",
    "                         'MarkerColor':  [jobInformation[\"MarkerColor\"].values[0]], \n",
    "                         'id' : [str(step[\"job\"])],\n",
    "                         'batchID' : [str(date) +  \"-\" + session  + \"-\" + str(vehicleID)],\n",
    "                                   })\n",
    "#                 print(new)\n",
    "                columns =[\"PUD Svc Area\",\"PUD Fac\",\"PUD Rte\",\"PUD Cycle\",\"Courier id\",\"Courier Type\",\"Customer Name\",\"Street\",\"zip\",\"City\",\"Act Dt\",\"Act Base\",\"Delivery Type\",\"Pickup Type\",\"Prod Grp\",\"Prod Code\",\"ShpCnt\",\"Pallets Pcs\",\"Parcel Pcs\",\"Total Pcs\",\"Weight\",\"AR dtm\",\"Act Tm\",\"Open\",\"Closed\",\"lat\",\"lgtd\",\"awb_booking\",\"Act Ckpt Code\",\"PuD Type\",\"Stop Code\",\"MarkerColor\",\"id\",\"batchID\"]\n",
    "#                 df = df[]]\n",
    "                df = df.append(new)\n",
    "            else:\n",
    "                print(\"unprepare situation 1\")\n",
    "         #last record = end\n",
    "        timeIntervalMorning = getTimeWindowWithSession(\"m\")\n",
    "        timeIntervalAfternoon = getTimeWindowWithSession(\"a\")\n",
    "    #     session = \"aaa\"\n",
    "    #     getMiliSec(x[\"Act Tm\"]) > getMiliSec(\"14:00:00\") ) & (getMiliSec(x[\"Act Tm\"]) < getMiliSec(\"23:59:00\")  \n",
    "    #     print(getMiliSec(df.iloc[-1][\"Act Tm\"]))\n",
    "    #     print(getMiliSec(timeIntervalMorning[0]))\n",
    "    #     print(type(getMiliSec(timeIntervalMorning[0])))\n",
    "\n",
    "    #     if(getMiliSec(df.iloc[-1][\"Act Tm\"]) > timeIntervalMorning[0] and getMiliSec(df.iloc[-1][\"Act Tm\"]) <= timeIntervalMorning[1]):\n",
    "    #         session = \"m\"\n",
    "    #         print(\"afternoon\")\n",
    "    #     elif(getMiliSec(df.iloc[-1][\"Act Tm\"]) > timeIntervalAfternoon[0] and getMiliSec(df.iloc[-1][\"Act Tm\"]) <= timeIntervalAfternoon[1]):\n",
    "    #         session = \"a\"\n",
    "    #         print(\"morning\")\n",
    "    #     else:\n",
    "    #         print(\"unprepare situation 2\")\n",
    "\n",
    "        \n",
    "        \n",
    "        string = df.to_csv(None, index=False, columns = columns)\n",
    "        blob = bucket.blob(\"files/february/response/\"+ str(date) +  \"-\" + session  + \"-\" + vehicleID + \".csv\")\n",
    "#         print(\"files/february/response/\"+ str(date) +  \"-\" + session  + \"-\" + str(vehicleInformation['id']) + \".csv\" )\n",
    "#         print(str(vehicleInformation['id'].astype(\"int\")) + \".csv\" )\n",
    "\n",
    "        blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "\n",
    "#         df.to_csv(\"routes/\"+ str(date) + \"/\" +session  + \"/\" + str(name) + \".csv\", index=False)\n",
    "        print(\"created csv file . . ..\")\n",
    "#         print(df)\n",
    "        handleOptimalRoute(df, columns)\n",
    "\n",
    "    blob = bucket.blob(getInputeForResponseFileName(date,session))\n",
    "    content = json.dumps(dict_t, cls=NpEncoder) #the processed routes\n",
    "    blob.upload_from_string(content, \"application/json\")\n",
    "    print(\"created updated response json file\")\n",
    "\n",
    "def tryGotUnassignedInResponse2(date : str,  session: str, street: None, unassignedJob =None ):\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "\n",
    "    fullDataFrame = pd.read_csv(gStorage)\n",
    "    tempLen = len(fullDataFrame)\n",
    "    fullDataFrame = fullDataFrame.loc[(fullDataFrame['Courier Type'] != \"NON_GCA5\") ]\n",
    "    tempLen2 = len(fullDataFrame)\n",
    "    if(tempLen> tempLen2):\n",
    "        fullDataFrame.reset_index()\n",
    "    #initial id column\n",
    "    if 'id' not in fullDataFrame .columns:\n",
    "        fullDataFrame[\"id\"] = fullDataFrame.index+1\n",
    "    \n",
    "    # fullDataFrame = pd.read_csv(csvPath)\n",
    "    \n",
    "#     if(street == street):\n",
    "#         fullDataFrame, newAwbBooking = addJob(fullDataFrame, date, session, street)\n",
    "\n",
    "    courierAndZip = fullDataFrame[[\"Courier id\", \"zip\"]]\n",
    "    courierAndZip = courierAndZip[fullDataFrame['zip'].notna()]\n",
    "    courierAndZip = courierAndZip[courierAndZip[\"zip\"].astype(str).str.isdigit()] \n",
    "    zipSet = courierAndZip.groupby([\"Courier id\"])[\"zip\"].aggregate(lambda x: set(map(int, x)))\n",
    "    partialDataFrame = fullDataFrame\n",
    "    partialDataFrame = partialDataFrame.loc[partialDataFrame['Act Dt'] == int(date)]\n",
    "    deliveryListRoute, fullDataFrame = getDeliveryRoute(partialDataFrame, fullDataFrame, session)\n",
    "    jobsList, vehicleList = createJobsAndVehiclesList(deliveryListRoute, getTimeWindowWithSession(session), zipSet)\n",
    "    \n",
    "    dict_t = createDictionaryObjectJobsVehicles(jobsList,vehicleList)\n",
    "    print(len(deliveryListRoute))\n",
    "#     print(deliveryListRoute)\n",
    "#     print( dict_t)\n",
    "#     print(vehicleList[0].time_window)\n",
    "\n",
    "    content = json.dumps(dict_t, cls=NpEncoder) \n",
    "    \n",
    "    blob = bucket.blob(getInputeForResponseFileName(date,session))\n",
    "\n",
    "    blob.upload_from_string(content, \"application/json\")\n",
    "\n",
    "    headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    r = requests.post(url, data=content, headers=headers)    \n",
    "    \n",
    "    if (r.status_code != 200) :\n",
    "        print (\"Error request code : \")\n",
    "        print(r.status_code)\n",
    "        print(r.content)\n",
    "#         print(dict_t)\n",
    "    \n",
    "    else:\n",
    "#         blob = bucket.blob(getResponseFileName(date, session))\n",
    "\n",
    "#         blob.upload_from_string(r.content, \"application/json\")\n",
    "        dict_t = json.loads(r.content)\n",
    "        processRoutedResponse(fullDataFrame, dict_t, session)\n",
    "        \n",
    "    #     #update the added job to csv\n",
    "#         newJobDataFrame = fullDataFrame.loc[(fullDataFrame[\"awb_booking\"] == newAwbBooking)]\n",
    "# \n",
    "    #     #temp fix\n",
    "#         fullDataFrame.at[newJobDataFrame.index[0], \"Courier Type\"] = \"NON_GCA5\"\n",
    "\n",
    "        string = fullDataFrame.to_csv(None, index=False)\n",
    "\n",
    "        blob = bucket.blob(csvPath)\n",
    "\n",
    "        blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "\n",
    "        dict_t = json.loads(r.content)\n",
    "#         dict_t[\"extra\"] = {}\n",
    "\n",
    "#         dict_t[\"extra\"][\"awb_booking\"] = newAwbBooking\n",
    "\n",
    "        responseDict = gotUnssigned(dict_t)\n",
    "\n",
    "#     print(dict_t)\n",
    "    # print(responseDict == [])#\n",
    "#     print(content)\n",
    "    return dict_t\n",
    "\n",
    "def uploadFile(fileName, content, bucketName = bucketName):\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "    \n",
    "    blob = bucket.blob(fileName)\n",
    "    name, extensionName = fileName.split(\".\")\n",
    "    if(extensionName == \"csv\"):\n",
    "        print(\"csv upload\")\n",
    "#         string = fullDataFrame.to_csv(None, index=False)\n",
    "        blob.upload_from_string(content, \"application/vnd.ms-excel\")\n",
    "    elif(extensionName == \"json\"):\n",
    "        blob.upload_from_string(content, \"application/json\")\n",
    "    else: \n",
    "        print(\"file not support by this function yet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#api part for chen wei\n",
    "def getRoutedGeocode(rowID : int) -> list:\n",
    "    df = pd.read_csv(gStorageOptimalCsv)\n",
    "    job = df.loc[df[\"id\"].astype('int') == rowID]\n",
    "    if(job.empty):\n",
    "        return \"rowID not find\"\n",
    "    else:\n",
    "        jobs = df.loc[df[\"batchID\"] == job[\"batchID\"].values[0] ]\n",
    "        if(jobs.empty):\n",
    "            return \"contact admin\"\n",
    "        else:\n",
    "            return jobs[\"lat\"].to_list(), jobs[\"lgtd\"].to_list()\n",
    "\n",
    "def getETAByID(rowID : int) -> str:\n",
    "    df = pd.read_csv(gStorageOptimalCsv)\n",
    "    job = df.loc[df[\"id\"].astype('int') == rowID]\n",
    "    if(job.empty):\n",
    "        return \"rowID not find\"\n",
    "    else:\n",
    "        return job[\"Act Tm\"].values[0]\n",
    "\n",
    "def makeTempDataFrameRow(df):\n",
    "    df[\"Courier Type\"] = \"NON_GCA5\"\n",
    "    return df\n",
    "    \n",
    "def changeTime(rowID : int, start: str, end : str ) -> list:\n",
    "    df = pd.read_csv(gStorageOptimalCsv)\n",
    "    dfJob=df.loc[df[\"id\"].astype('int') == rowID]\n",
    "#     print(len(dfJob))\n",
    "    fullDataFrame = pd.read_csv(gStorage)\n",
    "    fullDataFrame = fullDataFrame.loc[(fullDataFrame['Courier Type'] != \"NON_GCA5\") ]\n",
    "    if(dfJob.empty):\n",
    "        return \"rowID not find\"\n",
    "    session = getSessionWithTimeWindow(start, end)\n",
    "    print(session)\n",
    "    if(session not in [\"m\", \"a\"]):\n",
    "        return \"time interval error\"\n",
    "\n",
    "    courierAndZip = fullDataFrame[[\"Courier id\", \"zip\"]]\n",
    "    courierAndZip = courierAndZip[fullDataFrame['zip'].notna()]\n",
    "    courierAndZip = courierAndZip[courierAndZip[\"zip\"].astype(str).str.isdigit()] \n",
    "    zipSet = courierAndZip.groupby([\"Courier id\"])[\"zip\"].aggregate(lambda x: set(map(int, x)))\n",
    "    partialDataFrame = df\n",
    "    partialDataFrame = partialDataFrame.loc[partialDataFrame['batchID'] == dfJob[\"batchID\"].values[0]]\n",
    "    deliveryListRoute, df = getDeliveryRoute(partialDataFrame, df, session)\n",
    "    jobsList, vehicleList = createJobsAndVehiclesList(deliveryListRoute, getTimeWindowWithSession(session), zipSet)\n",
    "    for job in jobsList:\n",
    "        if(job.id == rowID):\n",
    "            job.time_windows = [getTimeWindow(start, end)]\n",
    "            break\n",
    "    dict_t = createDictionaryObjectJobsVehicles(jobsList,vehicleList)\n",
    "    content = json.dumps(dict_t, cls=NpEncoder) \n",
    "    headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    r = requests.post(url, data=content, headers=headers)    \n",
    "    \n",
    "    if (r.status_code != 200) :\n",
    "        print (\"Error request code : \")\n",
    "        print(r.status_code)\n",
    "        print(r.content)\n",
    "    \n",
    "    else:\n",
    "        dict_t = json.loads(r.content)\n",
    "        if(dict_t[\"summary\"][\"unassigned\"] > 0):\n",
    "            return \"could not fit the time range\"\n",
    "        else:\n",
    "            print(\"here\")\n",
    "            temp = dfJob.copy()\n",
    "            temp[\"Open\"] = start\n",
    "            temp[\"Closed\"] = end\n",
    "            temp[\"Courier Type\"] = \"NON_GCA5\"\n",
    "            df = addRowToDataFrame(dfJob.index[0] + 1, df, temp.iloc[0])\n",
    "            uploadFile(optimalCsvPath ,df.to_csv(None, index=False))\n",
    "#             uploadFile(dfJob[\"batchID\"].values[0] + \"-temp\"+ str(job[\"id\"].values[0]) +\"-response.json\", r.content, bucketTempName)\n",
    "            return \"possible, update with id \" + str(rowID)\n",
    "\n",
    "def confirmChangeTime(rowID : str):\n",
    "    from time import strftime\n",
    "    from time import gmtime    \n",
    "    df = pd.read_csv(gStorageOptimalCsv)\n",
    "    dfJob = df.loc[df[\"id\"].astype('int') == rowID]\n",
    "    if(dfJob.empty):\n",
    "        return \"id not found\"\n",
    "    tempJob = df.loc[(df[\"id\"].astype('int') == rowID) & (df[\"Courier Type\"] == \"NON_GCA5\" )]\n",
    "    \n",
    "    tempJob[\"Courier Type\"] =  dfJob[\"Courier Type\"]\n",
    "    df = df.drop(dfJob.index[0])\n",
    "    start = tempJob[\"Open\"].values[0]\n",
    "    end = tempJob[\"Closed\"].values[0]\n",
    "    session = getSessionWithTimeWindow(start,end)\n",
    "    \n",
    "\n",
    "    \n",
    "    fullDataFrame = pd.read_csv(gStorage)\n",
    "    fullDataFrame = fullDataFrame.loc[(fullDataFrame['Courier Type'] != \"NON_GCA5\") ]\n",
    "    if(session not in [\"m\", \"a\"]):\n",
    "        return \"time interval error\"\n",
    "    \n",
    "    courierAndZip = fullDataFrame[[\"Courier id\", \"zip\"]]\n",
    "    courierAndZip = courierAndZip[fullDataFrame['zip'].notna()]\n",
    "    courierAndZip = courierAndZip[courierAndZip[\"zip\"].astype(str).str.isdigit()] \n",
    "    zipSet = courierAndZip.groupby([\"Courier id\"])[\"zip\"].aggregate(lambda x: set(map(int, x)))\n",
    "    partialDataFrame = df\n",
    "    partialDataFrame = partialDataFrame.loc[partialDataFrame['batchID'] == dfJob[\"batchID\"].values[0]]\n",
    "    deliveryListRoute, df = getDeliveryRoute(partialDataFrame, df, session)\n",
    "    jobsList, vehicleList = createJobsAndVehiclesList(deliveryListRoute, getTimeWindowWithSession(session), zipSet)\n",
    "    for job in jobsList:\n",
    "        if(job.id == rowID):\n",
    "            job.time_windows = [getTimeWindow(start, end)]\n",
    "            break\n",
    "    dict_t = createDictionaryObjectJobsVehicles(jobsList,vehicleList)\n",
    "    content = json.dumps(dict_t, cls=NpEncoder) \n",
    "    headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "    r = requests.post(url, data=content, headers=headers)    \n",
    "    \n",
    "    if (r.status_code != 200) :\n",
    "        print (\"Error request code : \")\n",
    "        print(r.status_code)\n",
    "        print(r.content)\n",
    "    \n",
    "    else:\n",
    "        dict_t = json.loads(r.content)\n",
    "        if(dict_t[\"summary\"][\"unassigned\"] > 0):\n",
    "            return \"could not fit the time range\"\n",
    "        else:\n",
    "            uploadFile(optimalCsvPath ,df.to_csv(None, index=False))\n",
    "            uploadFile(dfJob[\"batchID\"].values[0] + \"-temp\"+ str(dfJob[\"id\"].values[0]) +\"-response.json\", r.content, bucketTempName)\n",
    "    \n",
    "    responseFile = \"gs://real-bucket-dhl/files/february/response/\" + str(dfJob[\"batchID\"].values[0]) + \"-temp-response.json\"\n",
    "    \n",
    "    client = storage.Client()\n",
    "    \n",
    "    if (not checkGFileExists(str(dfJob[\"batchID\"].values[0]) + \"-temp\"+ str(dfJob[\"id\"].values[0]) +\"-response.json\", bucketTempName)):\n",
    "        return \"temp file not exist\"\n",
    "    bucket = client.get_bucket(bucketTempName)\n",
    "    blob = bucket.get_blob(str(dfJob[\"batchID\"].values[0]) + \"-temp\"+ str(dfJob[\"id\"].values[0]) +\"-response.json\")\n",
    "    json_data = blob.download_as_string()\n",
    "    blob.delete()\n",
    "    \n",
    "    if (not checkGFileExists(\"files/february/response/\" + str(dfJob[\"batchID\"].values[0]) + \"-response.json\")):\n",
    "        print(\"old file not exist\")\n",
    "    else:\n",
    "        bucket = client.get_bucket(bucketName)\n",
    "        blobOld = bucket.get_blob(\"files/february/response/\" + str(dfJob[\"batchID\"].values[0]) + \"-response.json\")\n",
    "        blobOld.delete()\n",
    "    \n",
    "    dict_t = json.loads(json_data)\n",
    "    \n",
    "#     df.at[job.index[0], [\"Open\"]]  = strftime(\"%H:%M:%S\", gmtime(start))\n",
    "#     df.at[job.index[0], [\"Closed\"]]  = strftime(\"%H:%M:%S\", gmtime(end))\n",
    "    processRoutedResponse(df, dict_t,session)\n",
    "    return \"success. . .\"\n",
    "\n",
    "def getTimeWindowFromResponsedict(dict_t : dict, idToFind)->list:\n",
    "    for route in dict_t[\"routes\"]:\n",
    "        for step in route[\"steps\"]:\n",
    "            if(step[\"type\"] == \"job\"):\n",
    "                if(step[\"job\"] == idToFind):\n",
    "                    start = step[\"arrival\"]\n",
    "                    end = step[\"arrival\"] + step[\"duration\"]\n",
    "                    break\n",
    "    return start,end\n",
    "\n",
    "def changeJob(data):\n",
    "    from numpy import nan as Nan\n",
    "    if(not is_json(data)):\n",
    "        return \"not json\"\n",
    "    else:\n",
    "        dict_t = json.loads(data)\n",
    "        fullDF = pd.read_csv(gStorage)\n",
    "        if(fullDF.empty):\n",
    "            return \"file empty\"\n",
    "        fullDF = fullDF.loc[(fullDF['Courier Type'] != \"NON_GCA5\") ]\n",
    "        dict_t[\"PUD Svc Area\"] = \"KUL\"\n",
    "        dict_t[\"PUD Fac\"] = \"EAC\"\n",
    "        dict_t[\"PUD Rte\"] = \"ACA1\"\n",
    "        dict_t[\"PUD Cycle\"] = \"B\"\n",
    "        dict_t[\"Courier id\"] = \"rafinord\"\n",
    "        dict_t[\"Courier Type\"] = \"NON_GCA5\"\n",
    "        dict_t[\"Delivery Type\"] = \"NORMAL\"\n",
    "        dict_t[\"Pickup Type\"] = \"REGULAR\"\n",
    "        dict_t[\"ShpCnt\"] = 0\n",
    "        dict_t[\"Pallets Pcs\"] = 0\n",
    "        dict_t[\"Parcel Pcs\"] = 0\n",
    "        dict_t[\"AR dtm\"] = pd.Series([np.nan])\n",
    "        dict_t[\"Act Tm\"] = dict_t[\"Open\"]\n",
    "#         dict_t[\"Open\"] = \"B\"\n",
    "#         dict_t[\"Closed\"] = \"B\"\n",
    "        dict_t[\"lat\"] = pd.Series([np.nan])\n",
    "        dict_t[\"lgtd\"] = pd.Series([np.nan])\n",
    "        dict_t[\"awb_booking\"] = \"awb_booking\" + str(len(fullDF) + 1)\n",
    "        dict_t[\"Act Ckpt Code\"] = \"PU\"\n",
    "        dict_t[\"PuD Type\"] = \"PU\"\n",
    "        dict_t[\"Stop Code\"] = 111\n",
    "        dict_t[\"MarkerColor\"] = pd.Series([np.nan])\n",
    "        dict_t[\"id\"] = str(len(fullDF) + 1)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(dict_t)\n",
    "#         df = pd.DataFrame.from_records(dict_t, index = [0], columns = fullDF.columns)\n",
    "#         print(df.columns)\n",
    "#         print(df[\"PUD Svc Area\"])\n",
    "    \n",
    "        partialDataFrame = fullDF.loc[(fullDF['Courier id'] == \"rafinord\") & (fullDF[\"Act Dt\"] == int(df[\"Act Dt\"])) & (fullDF[\"Act Ckpt Code\"] == \"DEPAR\")]\n",
    "        fullDF = addRowToDataFrame(partialDataFrame.index[0] + 1, fullDF, df.iloc[0])\n",
    "        uploadFile(csvPath, fullDF.to_csv(None, index=False))\n",
    "        return \"confirm with id \" + str(df[\"id\"].values[0])\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json_object = json.loads(myjson)\n",
    "    except ValueError as e:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def confirmAddJob(rowID : int):\n",
    "        fullDF = pd.read_csv(gStorage)\n",
    "        if(fullDF.empty):\n",
    "            return \"file empty\"\n",
    "        selectedDF = fullDF.loc[(fullDF[\"id\"].astype(int) == rowID) & (fullDF[\"Courier Type\"] == \"NON_GCA5\")]\n",
    "        if(selectedDF.empty):\n",
    "            return \"id not found\"\n",
    "        fullDF.at[selectedDF.index, \"Courier Type\"] = \"DHL Courier\" \n",
    "        uploadFile(csvPath, fullDF.to_csv(None, index=False))\n",
    "        return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucketName)\n",
    "fullDataFrame = pd.read_csv(gStorageOptimalCsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act Dt\n",
      "Friday       1371\n",
      "Monday       1430\n",
      "Saturday      258\n",
      "Thursday     1408\n",
      "Tuesday      1047\n",
      "Wednesday    1383\n",
      "Name: id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucketName)\n",
    "fullDataFrame = pd.read_csv(gStorageOptimalCsv)\n",
    "from numpy import nan as Nan\n",
    "fullDataFrame\n",
    "fullDataFrame['Act Tm'] = pd.to_datetime(fullDataFrame['Act Tm'])\n",
    "fullDataFrame['Act Tm'] = [time.time() for time in fullDataFrame['Act Tm']]\n",
    "time = datetime.datetime.strptime(morningStart, '%H:%M:%S').time()\n",
    "time2 = datetime.datetime.strptime(morningEnd, '%H:%M:%S').time()\n",
    "maskVehicle = (fullDataFrame[\"Act Ckpt Code\"] == \"DEPAR\") | (fullDataFrame[\"Act Ckpt Code\"] == \"ARRVD\")\n",
    "tasks = fullDataFrame.loc[~ (maskVehicle)]\n",
    "# print(tasks)\n",
    "\n",
    "dfVehicle = fullDataFrame.loc[maskVehicle]\n",
    "dateList = [20200201]\n",
    "dfXDayVehicle = dfVehicle.loc[dfVehicle[\"Act Dt\"].astype(int).isin(dateList)]\n",
    "\n",
    "# dateDF = pd.to_datetime(fullDataFrame[\"Act Dt\"], format='%Y%m%d')\n",
    "fullDataFrame[\"Act Dt\"] = pd.to_datetime(fullDataFrame[\"Act Dt\"], format='%Y%m%d')\n",
    "dateDF = fullDataFrame.groupby(fullDataFrame['Act Dt'].dt.weekday_name)[\"id\"].nunique()\n",
    "dayDF = fullDataFrame.groupby(fullDataFrame['Act Dt'].dt.day)[\"id\"].nunique()\n",
    "\n",
    "print (dateDF)                                      \n",
    "sessionMMask = ((tasks['Act Tm'] >= time) & (tasks['Act Tm'] <= time2)) \n",
    "sessionMMask.value_counts()\n",
    "\n",
    "morning = tasks.loc[sessionMMask]\n",
    "afternoon = tasks.loc[~sessionMMask]\n",
    "\n",
    "type(dayDF.astype(int))\n",
    "dayDF.astype(int)[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"20200201-m-1\": \"20200201-m-1\", \"20200201-m-15\": \"20200201-m-15\", \"20200201-m-32\": \"20200201-m-32\", \"20200201-m-34\": \"20200201-m-34\", \"20200201-m-49\": \"20200201-m-49\", \"20200203-a-58\": \"20200203-a-58\", \"20200203-a-82\": \"20200203-a-82\", \"20200203-a-117\": \"20200203-a-117\", \"20200203-a-154\": \"20200203-a-154\", \"20200203-a-187\": \"20200203-a-187\", \"20200203-a-211\": \"20200203-a-211\", \"20200203-a-236\": \"20200203-a-236\", \"20200203-a-267\": \"20200203-a-267\", \"20200203-a-270\": \"20200203-a-270\", \"20200203-a-304\": \"20200203-a-304\", \"20200203-a-311\": \"20200203-a-311\", \"20200203-a-382\": \"20200203-a-382\", \"20200203-m-58\": \"20200203-m-58\", \"20200203-m-82\": \"20200203-m-82\", \"20200203-m-117\": \"20200203-m-117\", \"20200203-m-154\": \"20200203-m-154\", \"20200203-m-187\": \"20200203-m-187\", \"20200203-m-211\": \"20200203-m-211\", \"20200203-m-236\": \"20200203-m-236\", \"20200203-m-267\": \"20200203-m-267\", \"20200203-m-270\": \"20200203-m-270\", \"20200203-m-304\": \"20200203-m-304\", \"20200203-m-311\": \"20200203-m-311\", \"20200203-m-382\": \"20200203-m-382\", \"20200204-a-447\": \"20200204-a-447\", \"20200204-a-472\": \"20200204-a-472\", \"20200204-a-499\": \"20200204-a-499\", \"20200204-a-530\": \"20200204-a-530\", \"20200204-a-553\": \"20200204-a-553\", \"20200204-a-573\": \"20200204-a-573\", \"20200205-a-769\": \"20200205-a-769\", \"20200205-a-808\": \"20200205-a-808\", \"20200205-a-840\": \"20200205-a-840\", \"20200205-a-876\": \"20200205-a-876\", \"20200205-a-905\": \"20200205-a-905\", \"20200205-a-926\": \"20200205-a-926\", \"20200205-a-944\": \"20200205-a-944\", \"20200205-a-977\": \"20200205-a-977\", \"20200205-a-980\": \"20200205-a-980\", \"20200205-a-1004\": \"20200205-a-1004\", \"20200205-a-1009\": \"20200205-a-1009\", \"20200205-a-1071\": \"20200205-a-1071\", \"20200205-m-769\": \"20200205-m-769\", \"20200205-m-808\": \"20200205-m-808\", \"20200205-m-840\": \"20200205-m-840\", \"20200205-m-876\": \"20200205-m-876\", \"20200205-m-905\": \"20200205-m-905\", \"20200205-m-926\": \"20200205-m-926\", \"20200205-m-944\": \"20200205-m-944\", \"20200205-m-977\": \"20200205-m-977\", \"20200205-m-980\": \"20200205-m-980\", \"20200205-m-1004\": \"20200205-m-1004\", \"20200205-m-1009\": \"20200205-m-1009\", \"20200205-m-1071\": \"20200205-m-1071\", \"20200205-m-1100\": \"20200205-m-1100\", \"20200206-a-1135\": \"20200206-a-1135\", \"20200206-a-1160\": \"20200206-a-1160\", \"20200206-a-1194\": \"20200206-a-1194\", \"20200206-a-1230\": \"20200206-a-1230\", \"20200206-a-1262\": \"20200206-a-1262\", \"20200206-a-1283\": \"20200206-a-1283\", \"20200206-a-1310\": \"20200206-a-1310\", \"20200206-a-1332\": \"20200206-a-1332\", \"20200206-a-1335\": \"20200206-a-1335\", \"20200206-a-1377\": \"20200206-a-1377\", \"20200206-a-1384\": \"20200206-a-1384\", \"20200206-m-1135\": \"20200206-m-1135\", \"20200206-m-1160\": \"20200206-m-1160\", \"20200206-m-1194\": \"20200206-m-1194\", \"20200206-m-1230\": \"20200206-m-1230\", \"20200206-m-1262\": \"20200206-m-1262\", \"20200206-m-1283\": \"20200206-m-1283\", \"20200206-m-1310\": \"20200206-m-1310\", \"20200206-m-1332\": \"20200206-m-1332\", \"20200206-m-1335\": \"20200206-m-1335\", \"20200206-m-1377\": \"20200206-m-1377\", \"20200206-m-1384\": \"20200206-m-1384\", \"20200206-m-1446\": \"20200206-m-1446\", \"20200207-a-1509\": \"20200207-a-1509\", \"20200207-a-1530\": \"20200207-a-1530\", \"20200207-a-1563\": \"20200207-a-1563\", \"20200207-a-1591\": \"20200207-a-1591\", \"20200207-a-1626\": \"20200207-a-1626\", \"20200207-a-1653\": \"20200207-a-1653\", \"20200207-a-1680\": \"20200207-a-1680\", \"20200207-a-1702\": \"20200207-a-1702\", \"20200207-a-1706\": \"20200207-a-1706\", \"20200207-a-1733\": \"20200207-a-1733\", \"20200207-a-1742\": \"20200207-a-1742\", \"20200207-a-1792\": \"20200207-a-1792\", \"20200207-a-1820\": \"20200207-a-1820\", \"20200207-m-1509\": \"20200207-m-1509\", \"20200207-m-1530\": \"20200207-m-1530\", \"20200207-m-1563\": \"20200207-m-1563\", \"20200207-m-1591\": \"20200207-m-1591\", \"20200207-m-1626\": \"20200207-m-1626\", \"20200207-m-1653\": \"20200207-m-1653\", \"20200207-m-1680\": \"20200207-m-1680\", \"20200207-m-1702\": \"20200207-m-1702\", \"20200207-m-1706\": \"20200207-m-1706\", \"20200207-m-1733\": \"20200207-m-1733\", \"20200207-m-1742\": \"20200207-m-1742\", \"20200207-m-1792\": \"20200207-m-1792\", \"20200207-m-1820\": \"20200207-m-1820\", \"20200210-a-1874\": \"20200210-a-1874\", \"20200210-a-1905\": \"20200210-a-1905\", \"20200210-a-1937\": \"20200210-a-1937\", \"20200210-a-1966\": \"20200210-a-1966\", \"20200210-a-2004\": \"20200210-a-2004\", \"20200210-a-2025\": \"20200210-a-2025\", \"20200210-a-2063\": \"20200210-a-2063\", \"20200210-a-2099\": \"20200210-a-2099\", \"20200210-a-2102\": \"20200210-a-2102\", \"20200210-a-2128\": \"20200210-a-2128\", \"20200210-a-2136\": \"20200210-a-2136\", \"20200210-a-2202\": \"20200210-a-2202\", \"20200210-a-2235\": \"20200210-a-2235\", \"20200210-a-2269\": \"20200210-a-2269\", \"20200210-m-1874\": \"20200210-m-1874\", \"20200210-m-1905\": \"20200210-m-1905\", \"20200210-m-1937\": \"20200210-m-1937\", \"20200210-m-1966\": \"20200210-m-1966\", \"20200210-m-2004\": \"20200210-m-2004\", \"20200210-m-2025\": \"20200210-m-2025\", \"20200210-m-2063\": \"20200210-m-2063\", \"20200210-m-2099\": \"20200210-m-2099\", \"20200210-m-2102\": \"20200210-m-2102\", \"20200210-m-2128\": \"20200210-m-2128\", \"20200210-m-2136\": \"20200210-m-2136\", \"20200210-m-2202\": \"20200210-m-2202\", \"20200210-m-2235\": \"20200210-m-2235\", \"20200211-a-2287\": \"20200211-a-2287\", \"20200211-a-2310\": \"20200211-a-2310\", \"20200211-a-2345\": \"20200211-a-2345\", \"20200211-a-2380\": \"20200211-a-2380\", \"20200211-a-2406\": \"20200211-a-2406\", \"20200211-a-2427\": \"20200211-a-2427\", \"20200211-a-2452\": \"20200211-a-2452\", \"20200211-a-2471\": \"20200211-a-2471\", \"20200211-a-2475\": \"20200211-a-2475\", \"20200211-a-2504\": \"20200211-a-2504\", \"20200211-a-2511\": \"20200211-a-2511\", \"20200211-a-2572\": \"20200211-a-2572\", \"20200211-m-2287\": \"20200211-m-2287\", \"20200211-m-2310\": \"20200211-m-2310\", \"20200211-m-2345\": \"20200211-m-2345\", \"20200211-m-2380\": \"20200211-m-2380\", \"20200211-m-2406\": \"20200211-m-2406\", \"20200211-m-2427\": \"20200211-m-2427\", \"20200211-m-2452\": \"20200211-m-2452\", \"20200211-m-2471\": \"20200211-m-2471\", \"20200211-m-2475\": \"20200211-m-2475\", \"20200211-m-2504\": \"20200211-m-2504\", \"20200211-m-2511\": \"20200211-m-2511\", \"20200211-m-2572\": \"20200211-m-2572\", \"20200212-a-2635\": \"20200212-a-2635\", \"20200212-a-2652\": \"20200212-a-2652\", \"20200212-a-2686\": \"20200212-a-2686\", \"20200212-a-2722\": \"20200212-a-2722\", \"20200212-a-2752\": \"20200212-a-2752\", \"20200212-a-2778\": \"20200212-a-2778\", \"20200212-a-2808\": \"20200212-a-2808\", \"20200212-a-2837\": \"20200212-a-2837\", \"20200212-a-2840\": \"20200212-a-2840\", \"20200212-a-2861\": \"20200212-a-2861\", \"20200212-a-2869\": \"20200212-a-2869\", \"20200212-a-2923\": \"20200212-a-2923\", \"20200212-m-2635\": \"20200212-m-2635\", \"20200212-m-2652\": \"20200212-m-2652\", \"20200212-m-2686\": \"20200212-m-2686\", \"20200212-m-2722\": \"20200212-m-2722\", \"20200212-m-2752\": \"20200212-m-2752\", \"20200212-m-2778\": \"20200212-m-2778\", \"20200212-m-2808\": \"20200212-m-2808\", \"20200212-m-2837\": \"20200212-m-2837\", \"20200212-m-2840\": \"20200212-m-2840\", \"20200212-m-2861\": \"20200212-m-2861\", \"20200212-m-2869\": \"20200212-m-2869\", \"20200212-m-2923\": \"20200212-m-2923\", \"20200213-a-2984\": \"20200213-a-2984\", \"20200213-a-3016\": \"20200213-a-3016\", \"20200213-a-3046\": \"20200213-a-3046\", \"20200213-a-3082\": \"20200213-a-3082\", \"20200213-a-3121\": \"20200213-a-3121\", \"20200213-a-3148\": \"20200213-a-3148\", \"20200213-a-3179\": \"20200213-a-3179\", \"20200213-a-3211\": \"20200213-a-3211\", \"20200213-a-3215\": \"20200213-a-3215\", \"20200213-a-3241\": \"20200213-a-3241\", \"20200213-a-3248\": \"20200213-a-3248\", \"20200213-a-3317\": \"20200213-a-3317\", \"20200213-a-3347\": \"20200213-a-3347\", \"20200213-m-2984\": \"20200213-m-2984\", \"20200213-m-3016\": \"20200213-m-3016\", \"20200213-m-3046\": \"20200213-m-3046\", \"20200213-m-3082\": \"20200213-m-3082\", \"20200213-m-3121\": \"20200213-m-3121\", \"20200213-m-3148\": \"20200213-m-3148\", \"20200213-m-3179\": \"20200213-m-3179\", \"20200213-m-3211\": \"20200213-m-3211\", \"20200213-m-3215\": \"20200213-m-3215\", \"20200213-m-3241\": \"20200213-m-3241\", \"20200213-m-3248\": \"20200213-m-3248\", \"20200213-m-3317\": \"20200213-m-3317\", \"20200213-m-3347\": \"20200213-m-3347\", \"20200214-a-3386\": \"20200214-a-3386\", \"20200214-a-3402\": \"20200214-a-3402\", \"20200214-a-3440\": \"20200214-a-3440\", \"20200214-a-3463\": \"20200214-a-3463\", \"20200214-a-3495\": \"20200214-a-3495\", \"20200214-a-3518\": \"20200214-a-3518\", \"20200214-a-3540\": \"20200214-a-3540\", \"20200214-a-3563\": \"20200214-a-3563\", \"20200214-a-3567\": \"20200214-a-3567\", \"20200214-a-3589\": \"20200214-a-3589\", \"20200214-a-3597\": \"20200214-a-3597\", \"20200214-a-3658\": \"20200214-a-3658\", \"20200214-a-3690\": \"20200214-a-3690\", \"20200214-m-3386\": \"20200214-m-3386\", \"20200214-m-3402\": \"20200214-m-3402\", \"20200214-m-3440\": \"20200214-m-3440\", \"20200214-m-3463\": \"20200214-m-3463\", \"20200214-m-3495\": \"20200214-m-3495\", \"20200214-m-3518\": \"20200214-m-3518\", \"20200214-m-3540\": \"20200214-m-3540\", \"20200214-m-3563\": \"20200214-m-3563\", \"20200214-m-3567\": \"20200214-m-3567\", \"20200214-m-3589\": \"20200214-m-3589\", \"20200214-m-3597\": \"20200214-m-3597\", \"20200214-m-3658\": \"20200214-m-3658\", \"20200215-m-3729\": \"20200215-m-3729\", \"20200215-m-3744\": \"20200215-m-3744\", \"20200215-m-3765\": \"20200215-m-3765\", \"20200215-m-3769\": \"20200215-m-3769\", \"20200215-m-3788\": \"20200215-m-3788\", \"20200217-a-3806\": \"20200217-a-3806\", \"20200217-a-3831\": \"20200217-a-3831\", \"20200217-a-3857\": \"20200217-a-3857\", \"20200217-a-3894\": \"20200217-a-3894\", \"20200217-a-3937\": \"20200217-a-3937\", \"20200217-a-3957\": \"20200217-a-3957\", \"20200217-a-3983\": \"20200217-a-3983\", \"20200217-a-4004\": \"20200217-a-4004\", \"20200217-a-4007\": \"20200217-a-4007\", \"20200217-a-4035\": \"20200217-a-4035\", \"20200217-a-4043\": \"20200217-a-4043\", \"20200217-a-4107\": \"20200217-a-4107\", \"20200217-a-4140\": \"20200217-a-4140\", \"20200217-a-4180\": \"20200217-a-4180\", \"20200217-m-3806\": \"20200217-m-3806\", \"20200217-m-3831\": \"20200217-m-3831\", \"20200217-m-3857\": \"20200217-m-3857\", \"20200217-m-3894\": \"20200217-m-3894\", \"20200217-m-3937\": \"20200217-m-3937\", \"20200217-m-3957\": \"20200217-m-3957\", \"20200217-m-3983\": \"20200217-m-3983\", \"20200217-m-4004\": \"20200217-m-4004\", \"20200217-m-4007\": \"20200217-m-4007\", \"20200217-m-4035\": \"20200217-m-4035\", \"20200217-m-4043\": \"20200217-m-4043\", \"20200217-m-4107\": \"20200217-m-4107\", \"20200217-m-4140\": \"20200217-m-4140\", \"20200218-a-4195\": \"20200218-a-4195\", \"20200218-a-4213\": \"20200218-a-4213\", \"20200218-a-4249\": \"20200218-a-4249\", \"20200218-a-4273\": \"20200218-a-4273\", \"20200218-a-4307\": \"20200218-a-4307\", \"20200218-a-4331\": \"20200218-a-4331\", \"20200218-a-4352\": \"20200218-a-4352\", \"20200218-a-4368\": \"20200218-a-4368\", \"20200218-a-4371\": \"20200218-a-4371\", \"20200218-a-4389\": \"20200218-a-4389\", \"20200218-a-4398\": \"20200218-a-4398\", \"20200218-m-4195\": \"20200218-m-4195\", \"20200218-m-4213\": \"20200218-m-4213\", \"20200218-m-4249\": \"20200218-m-4249\", \"20200218-m-4273\": \"20200218-m-4273\", \"20200218-m-4307\": \"20200218-m-4307\", \"20200218-m-4331\": \"20200218-m-4331\", \"20200218-m-4352\": \"20200218-m-4352\", \"20200218-m-4368\": \"20200218-m-4368\", \"20200218-m-4371\": \"20200218-m-4371\", \"20200218-m-4389\": \"20200218-m-4389\", \"20200218-m-4398\": \"20200218-m-4398\", \"20200218-m-4467\": \"20200218-m-4467\", \"20200219-a-4526\": \"20200219-a-4526\", \"20200219-a-4556\": \"20200219-a-4556\", \"20200219-a-4584\": \"20200219-a-4584\", \"20200219-a-4615\": \"20200219-a-4615\", \"20200219-a-4642\": \"20200219-a-4642\", \"20200219-a-4669\": \"20200219-a-4669\", \"20200219-a-4698\": \"20200219-a-4698\", \"20200219-a-4726\": \"20200219-a-4726\", \"20200219-a-4730\": \"20200219-a-4730\", \"20200219-a-4750\": \"20200219-a-4750\", \"20200219-a-4756\": \"20200219-a-4756\", \"20200219-a-4812\": \"20200219-a-4812\", \"20200219-a-4843\": \"20200219-a-4843\", \"20200219-m-4526\": \"20200219-m-4526\", \"20200219-m-4556\": \"20200219-m-4556\", \"20200219-m-4584\": \"20200219-m-4584\", \"20200219-m-4615\": \"20200219-m-4615\", \"20200219-m-4642\": \"20200219-m-4642\", \"20200219-m-4669\": \"20200219-m-4669\", \"20200219-m-4698\": \"20200219-m-4698\", \"20200219-m-4726\": \"20200219-m-4726\", \"20200219-m-4730\": \"20200219-m-4730\", \"20200219-m-4750\": \"20200219-m-4750\", \"20200219-m-4756\": \"20200219-m-4756\", \"20200219-m-4812\": \"20200219-m-4812\", \"20200220-a-4881\": \"20200220-a-4881\", \"20200220-a-4905\": \"20200220-a-4905\", \"20200220-a-4932\": \"20200220-a-4932\", \"20200220-a-4952\": \"20200220-a-4952\", \"20200220-a-4981\": \"20200220-a-4981\", \"20200220-a-5012\": \"20200220-a-5012\", \"20200220-a-5037\": \"20200220-a-5037\", \"20200220-a-5061\": \"20200220-a-5061\", \"20200220-a-5064\": \"20200220-a-5064\", \"20200220-a-5083\": \"20200220-a-5083\", \"20200220-a-5087\": \"20200220-a-5087\", \"20200220-a-5151\": \"20200220-a-5151\", \"20200220-m-4881\": \"20200220-m-4881\", \"20200220-m-4905\": \"20200220-m-4905\", \"20200220-m-4932\": \"20200220-m-4932\", \"20200220-m-4952\": \"20200220-m-4952\", \"20200220-m-4981\": \"20200220-m-4981\", \"20200220-m-5012\": \"20200220-m-5012\", \"20200220-m-5037\": \"20200220-m-5037\", \"20200220-m-5061\": \"20200220-m-5061\", \"20200220-m-5064\": \"20200220-m-5064\", \"20200220-m-5083\": \"20200220-m-5083\", \"20200220-m-5087\": \"20200220-m-5087\", \"20200220-m-5151\": \"20200220-m-5151\", \"20200221-a-5219\": \"20200221-a-5219\", \"20200221-a-5243\": \"20200221-a-5243\", \"20200221-a-5280\": \"20200221-a-5280\", \"20200221-a-5312\": \"20200221-a-5312\", \"20200221-a-5348\": \"20200221-a-5348\", \"20200221-a-5381\": \"20200221-a-5381\", \"20200221-a-5405\": \"20200221-a-5405\", \"20200221-a-5423\": \"20200221-a-5423\", \"20200221-a-5427\": \"20200221-a-5427\", \"20200221-a-5456\": \"20200221-a-5456\", \"20200221-a-5526\": \"20200221-a-5526\", \"20200221-a-5553\": \"20200221-a-5553\", \"20200221-m-5219\": \"20200221-m-5219\", \"20200221-m-5243\": \"20200221-m-5243\", \"20200221-m-5280\": \"20200221-m-5280\", \"20200221-m-5312\": \"20200221-m-5312\", \"20200221-m-5348\": \"20200221-m-5348\", \"20200221-m-5381\": \"20200221-m-5381\", \"20200221-m-5405\": \"20200221-m-5405\", \"20200221-m-5423\": \"20200221-m-5423\", \"20200221-m-5427\": \"20200221-m-5427\", \"20200221-m-5456\": \"20200221-m-5456\", \"20200221-m-5465\": \"20200221-m-5465\", \"20200221-m-5526\": \"20200221-m-5526\", \"20200222-m-5587\": \"20200222-m-5587\", \"20200222-m-5604\": \"20200222-m-5604\", \"20200222-m-5632\": \"20200222-m-5632\", \"20200222-m-5636\": \"20200222-m-5636\", \"20200222-m-5649\": \"20200222-m-5649\", \"20200224-a-5659\": \"20200224-a-5659\", \"20200224-a-5693\": \"20200224-a-5693\", \"20200224-a-5731\": \"20200224-a-5731\", \"20200224-a-5759\": \"20200224-a-5759\", \"20200224-a-5797\": \"20200224-a-5797\", \"20200224-a-5823\": \"20200224-a-5823\", \"20200224-a-5856\": \"20200224-a-5856\", \"20200224-a-5886\": \"20200224-a-5886\", \"20200224-a-5891\": \"20200224-a-5891\", \"20200224-a-5918\": \"20200224-a-5918\", \"20200224-a-5994\": \"20200224-a-5994\", \"20200224-a-6023\": \"20200224-a-6023\", \"20200224-a-6058\": \"20200224-a-6058\", \"20200224-m-5659\": \"20200224-m-5659\", \"20200224-m-5693\": \"20200224-m-5693\", \"20200224-m-5731\": \"20200224-m-5731\", \"20200224-m-5759\": \"20200224-m-5759\", \"20200224-m-5797\": \"20200224-m-5797\", \"20200224-m-5823\": \"20200224-m-5823\", \"20200224-m-5856\": \"20200224-m-5856\", \"20200224-m-5886\": \"20200224-m-5886\", \"20200224-m-5891\": \"20200224-m-5891\", \"20200224-m-5918\": \"20200224-m-5918\", \"20200224-m-5926\": \"20200224-m-5926\", \"20200224-m-5994\": \"20200224-m-5994\", \"20200224-m-6023\": \"20200224-m-6023\", \"20200225-a-6071\": \"20200225-a-6071\", \"20200225-a-6096\": \"20200225-a-6096\", \"20200225-a-6130\": \"20200225-a-6130\", \"20200225-a-6158\": \"20200225-a-6158\", \"20200225-a-6191\": \"20200225-a-6191\", \"20200225-a-6217\": \"20200225-a-6217\", \"20200225-a-6239\": \"20200225-a-6239\", \"20200225-a-6262\": \"20200225-a-6262\", \"20200225-a-6266\": \"20200225-a-6266\", \"20200225-a-6290\": \"20200225-a-6290\", \"20200225-a-6357\": \"20200225-a-6357\", \"20200225-m-6071\": \"20200225-m-6071\", \"20200225-m-6096\": \"20200225-m-6096\", \"20200225-m-6130\": \"20200225-m-6130\", \"20200225-m-6158\": \"20200225-m-6158\", \"20200225-m-6191\": \"20200225-m-6191\", \"20200225-m-6217\": \"20200225-m-6217\", \"20200225-m-6239\": \"20200225-m-6239\", \"20200225-m-6262\": \"20200225-m-6262\", \"20200225-m-6266\": \"20200225-m-6266\", \"20200225-m-6290\": \"20200225-m-6290\", \"20200225-m-6299\": \"20200225-m-6299\", \"20200225-m-6357\": \"20200225-m-6357\", \"20200226-a-6422\": \"20200226-a-6422\", \"20200226-a-6451\": \"20200226-a-6451\", \"20200226-a-6478\": \"20200226-a-6478\", \"20200226-a-6522\": \"20200226-a-6522\", \"20200226-a-6558\": \"20200226-a-6558\", \"20200226-a-6580\": \"20200226-a-6580\", \"20200226-a-6598\": \"20200226-a-6598\", \"20200226-a-6619\": \"20200226-a-6619\", \"20200226-a-6623\": \"20200226-a-6623\", \"20200226-a-6654\": \"20200226-a-6654\", \"20200226-a-6661\": \"20200226-a-6661\", \"20200226-a-6736\": \"20200226-a-6736\", \"20200226-a-6768\": \"20200226-a-6768\", \"20200226-m-6422\": \"20200226-m-6422\", \"20200226-m-6451\": \"20200226-m-6451\", \"20200226-m-6478\": \"20200226-m-6478\", \"20200226-m-6522\": \"20200226-m-6522\", \"20200226-m-6558\": \"20200226-m-6558\", \"20200226-m-6580\": \"20200226-m-6580\", \"20200226-m-6598\": \"20200226-m-6598\", \"20200226-m-6619\": \"20200226-m-6619\", \"20200226-m-6623\": \"20200226-m-6623\", \"20200226-m-6654\": \"20200226-m-6654\", \"20200226-m-6661\": \"20200226-m-6661\", \"20200226-m-6736\": \"20200226-m-6736\", \"20200226-m-6768\": \"20200226-m-6768\", \"20200227-a-6799\": \"20200227-a-6799\", \"20200227-a-6817\": \"20200227-a-6817\", \"20200227-a-6852\": \"20200227-a-6852\", \"20200227-a-6880\": \"20200227-a-6880\", \"20200227-a-6914\": \"20200227-a-6914\", \"20200227-a-6944\": \"20200227-a-6944\", \"20200227-a-6969\": \"20200227-a-6969\", \"20200227-a-6993\": \"20200227-a-6993\", \"20200227-a-6997\": \"20200227-a-6997\", \"20200227-a-7021\": \"20200227-a-7021\", \"20200227-a-7091\": \"20200227-a-7091\", \"20200227-a-7125\": \"20200227-a-7125\", \"20200227-m-6799\": \"20200227-m-6799\", \"20200227-m-6817\": \"20200227-m-6817\", \"20200227-m-6852\": \"20200227-m-6852\", \"20200227-m-6880\": \"20200227-m-6880\", \"20200227-m-6914\": \"20200227-m-6914\", \"20200227-m-6944\": \"20200227-m-6944\", \"20200227-m-6969\": \"20200227-m-6969\", \"20200227-m-6993\": \"20200227-m-6993\", \"20200227-m-6997\": \"20200227-m-6997\", \"20200227-m-7021\": \"20200227-m-7021\", \"20200227-m-7031\": \"20200227-m-7031\", \"20200227-m-7091\": \"20200227-m-7091\", \"20200228-a-7165\": \"20200228-a-7165\", \"20200228-a-7198\": \"20200228-a-7198\", \"20200228-a-7233\": \"20200228-a-7233\", \"20200228-a-7254\": \"20200228-a-7254\", \"20200228-a-7289\": \"20200228-a-7289\", \"20200228-a-7322\": \"20200228-a-7322\", \"20200228-a-7347\": \"20200228-a-7347\", \"20200228-a-7376\": \"20200228-a-7376\", \"20200228-a-7380\": \"20200228-a-7380\", \"20200228-a-7410\": \"20200228-a-7410\", \"20200228-a-7472\": \"20200228-a-7472\", \"20200228-a-7505\": \"20200228-a-7505\", \"20200228-m-7165\": \"20200228-m-7165\", \"20200228-m-7198\": \"20200228-m-7198\", \"20200228-m-7233\": \"20200228-m-7233\", \"20200228-m-7254\": \"20200228-m-7254\", \"20200228-m-7289\": \"20200228-m-7289\", \"20200228-m-7322\": \"20200228-m-7322\", \"20200228-m-7347\": \"20200228-m-7347\", \"20200228-m-7376\": \"20200228-m-7376\", \"20200228-m-7380\": \"20200228-m-7380\", \"20200228-m-7410\": \"20200228-m-7410\", \"20200228-m-7419\": \"20200228-m-7419\", \"20200228-m-7472\": \"20200228-m-7472\", \"20200229-m-7538\": \"20200229-m-7538\", \"20200229-m-7555\": \"20200229-m-7555\", \"20200229-m-7576\": \"20200229-m-7576\", \"20200229-m-7580\": \"20200229-m-7580\", \"20200229-m-7598\": \"20200229-m-7598\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6629"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(bucketName)\n",
    "dfReturn = pd.read_csv(gStorageOptimalCsv)\n",
    "\n",
    "morningSSec = datetime.datetime.strptime(morningStart, '%H:%M:%S').time()\n",
    "morningESec = datetime.datetime.strptime(morningEnd, '%H:%M:%S').time()\n",
    "afternoonSSec = datetime.datetime.strptime(afternoonStart, '%H:%M:%S').time()\n",
    "afternoonESec = datetime.datetime.strptime(afternoonEnd, '%H:%M:%S').time()\n",
    "\n",
    "#vehicle\n",
    "def getVehicleInMonth(month = 2):\n",
    "    maskVehicle = (dfReturn[\"Act Ckpt Code\"] == \"DEPAR\") | (fullDataFrame[\"Act Ckpt Code\"] == \"ARRVD\")\n",
    "    dfVehicle = dfReturn.loc[maskVehicle]\n",
    "    return len(dfVehicle)\n",
    "\n",
    "def getVehicleDateInMonth(date,month =2):\n",
    "    maskVehicle = (dfReturn[\"Act Ckpt Code\"] == \"DEPAR\") | (fullDataFrame[\"Act Ckpt Code\"] == \"ARRVD\")\n",
    "    dfVehicle = dfReturn.loc[(maskVehicle) & (dfReturn[\"Act Dt\"].astype(int) == int(date)) ]\n",
    "    return len(dfVehicle)\n",
    "\n",
    "def getVehicleDateSessionInMonth(date,session,month = 2):\n",
    "    dfLocal = dfReturn.copy()\n",
    "    maskVehicle = (dfLocal[\"Act Ckpt Code\"] == \"DEPAR\") | (dfLocal[\"Act Ckpt Code\"] == \"ARRVD\")\n",
    "    dfLocal['Act Tm'] = pd.to_datetime(dfLocal['Act Tm'])\n",
    "    dfLocal['Act Tm'] = [time.time() for time in dfLocal['Act Tm']]\n",
    "    dfLocal = dfLocal.loc[(maskVehicle) & (dfLocal[\"Act Dt\"].astype(int).isin(date))]\n",
    "    if(session==\"m\"):\n",
    "        dfVehicle = dfVehicle.loc[(dfVehicle[\"Act Tm\"] >= morningSSec) & (dfVehicle[\"Act Tm\"] <= morningESec)]\n",
    "    elif(session==\"a\"):\n",
    "        dfVehicle = dfVehicle.loc[(dfVehicle[\"Act Tm\"] >= afternoonSSec) &(dfVehicle[\"Act Tm\"] <= afternoonESec)]\n",
    "    else:\n",
    "        return \"not prepared session\"\n",
    "                                  \n",
    "    return len(dfVehicle)\n",
    "\n",
    "#get routeIDS\n",
    "def getBatchID():\n",
    "    dfLocal = dfReturn.copy()\n",
    "    dfLocal = dfLocal[\"batchID\"].unique()\n",
    "#     print(type(list(dfLocal)))\n",
    "    dict_t = {}\n",
    "    for item in list(dfLocal):\n",
    "        dict_t[item] = item\n",
    "    return json.dumps(dict_t)\n",
    "#     print(dfLocal)\n",
    "    return dfLocal.to_json()\n",
    "\n",
    "def getRoute(batchID):\n",
    "    dfLocal = dfReturn.copy()\n",
    "    dfLocal = dfLocal.loc[dfLocal[\"batchID\"].isin(batchID)]\n",
    "#     dfLocal = dfLocal.loc[dfLocal[\"duration\"]]\n",
    "\n",
    "\n",
    "print(getBatchID())\n",
    "\n",
    "def getVehicle(courierID = None, date=None, action=None, s=None,weekDay=None, perDay=None):\n",
    "    dfLocal = dfReturn.copy()\n",
    "    dfLocal[\"Act Dt\"] = pd.to_datetime(dfReturn[\"Act Dt\"], format='%Y%m%d')\n",
    "    maskVehicle = (dfLocal[\"Act Ckpt Code\"] == \"DEPAR\") | (dfLocal[\"Act Ckpt Code\"] == \"ARRVD\")\n",
    "    dfLocal = dfLocal.loc[maskVehicle]\n",
    "    if(courierID):\n",
    "        dfLocal.loc[dfLocal[\"Courier id\"].isin(courierID)]\n",
    "    if(action):\n",
    "        dfLocal.loc[dfLocal[\"Act Base\"] == action]\n",
    "    if(date):\n",
    "        dfLocal.loc[dfLocal[\"Act Dt\"].isin(date)]\n",
    "    if(s):\n",
    "        dfLocal['Act Tm'] = pd.to_datetime(dfLocal['Act Tm'])\n",
    "        dfLocal['Act Tm'] = [time.time() for time in dfLocal['Act Tm']]\n",
    "        if(s==\"m\"):\n",
    "            dfLocal = dfLocal.loc[(dfLocal[\"Act Tm\"] >= morningSSec) & (dfLocal[\"Act Tm\"] <= morningESec)]\n",
    "        elif(s==\"a\"):\n",
    "            dfLocal = dfLocal.loc[(dfLocal[\"Act Tm\"] >= afternoonSSec) &(dfLocal[\"Act Tm\"] <= afternoonESec)]\n",
    "        else:\n",
    "            return \"not prepared session\"\n",
    "    if(weekDay):\n",
    "        dfLocal = dfLocal.groupby(dfLocal['Act Dt'].dt.weekday_name)[\"id\"].nunique()\n",
    "        return dfLocal.to_json()\n",
    "    if(perDay):\n",
    "        dfLocal = dfLocal.groupby(dfLocal['Act Dt'].dt.day)[\"id\"].nunique()\n",
    "        return dfLocal.to_json()\n",
    "    return len(dfLocal)\n",
    "\n",
    "def getJob(date=None, action=None, s=None,weekDay=None, perDay=None):\n",
    "    dfLocal = dfReturn.copy()\n",
    "    dfLocal[\"Act Dt\"] = pd.to_datetime(dfReturn[\"Act Dt\"], format='%Y%m%d')\n",
    "    maskVehicle = (dfLocal[\"Act Ckpt Code\"] == \"DEPAR\") | (dfLocal[\"Act Ckpt Code\"] == \"ARRVD\")\n",
    "    dfLocal = dfLocal.loc[~maskVehicle]\n",
    "    if(action):\n",
    "        dfLocal.loc[dfLocal[\"Act Base\"] == action]\n",
    "    if(date):\n",
    "        dfLocal.loc[dfLocal[\"Act Dt\"].isin(date)]\n",
    "    if(s):\n",
    "        dfLocal['Act Tm'] = pd.to_datetime(dfLocal['Act Tm'])\n",
    "        dfLocal['Act Tm'] = [time.time() for time in dfLocal['Act Tm']]\n",
    "        if(s==\"m\"):\n",
    "            dfLocal = dfLocal.loc[(dfLocal[\"Act Tm\"] >= morningSSec) & (dfLocal[\"Act Tm\"] <= morningESec)]\n",
    "        elif(s==\"a\"):\n",
    "            dfLocal = dfLocal.loc[(dfLocal[\"Act Tm\"] >= afternoonSSec) &(dfLocal[\"Act Tm\"] <= afternoonESec)]\n",
    "        else:\n",
    "            return \"not prepared session\"\n",
    "    if(weekDay):\n",
    "        dfLocal = dfLocal.groupby(dfLocal['Act Dt'].dt.weekday_name)[\"id\"].nunique()\n",
    "        return dfLocal.to_json()\n",
    "    if(perDay):\n",
    "        dfLocal = dfLocal.groupby(dfLocal['Act Dt'].dt.day)[\"id\"].nunique()\n",
    "        return dfLocal.to_json()\n",
    "    return len(dfLocal)\n",
    "#action\n",
    "def getJobInAction():\n",
    "    return []\n",
    "getJob([20200204,20200205 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ece573cb6218>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtimeO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Act Tm\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\MX-15\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'hour'"
     ]
    }
   ],
   "source": [
    "fullDataFrame['Act Tm']\n",
    "timeO = fullDataFrame['Act Tm'].iloc[1]\n",
    "type(fullDataFrame['Act Tm'].iloc[1])\n",
    "seconds = (timeO.hour * 60 + timeO.minute) * 60 + timeO.second\n",
    "seconds = (fullDataFrame['Act Tm'].hour * 60 + fullDataFrame['Act Tm'].minute) * 60 + fullDataFrame['Act Tm'].second\n",
    "\n",
    "df_time = fullDataFrame[\"Act Tm\"]\n",
    "df_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-b634209842e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mafternoonS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafternoonE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTimeWindowWithSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# print(getTimeWindowWithSession(\"a\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmorning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfullDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminute\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m60\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Act Tm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmorningStart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgetMiliSec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullDataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Act Tm\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmorningEnd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# print(morning)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\MX-15\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'hour'"
     ]
    }
   ],
   "source": [
    "uniqueCourierID = fullDataFrame[\"Courier id\"].unique()\n",
    "uniqueDate = fullDataFrame[\"Act Dt\"].unique()\n",
    "pick = fullDataFrame.loc[fullDataFrame[\"Act Base\"] == \"p\"]\n",
    "delivery = fullDataFrame.loc[fullDataFrame[\"Act Base\"] == \"d\"]\n",
    "morningS, morningE = getTimeWindowWithSession(\"m\")\n",
    "afternoonS, afternoonE = getTimeWindowWithSession(\"a\")\n",
    "# print(getTimeWindowWithSession(\"a\"))\n",
    "morning = fullDataFrame.loc[ ((fullDataFrame['Act Tm'].hour * 60 + fullDataFrame['Act Tm'].minute * 60 + fullDataFrame['Act Tm'].second) > morningStart) & (getMiliSec(fullDataFrame[\"Act Tm\"]).all() < morningEnd) ]\n",
    "# print(morning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20200201., 20200203., 20200204., 20200205., 20200206., 20200207.,\n",
       "       20200210., 20200211., 20200212., 20200213., 20200214., 20200215.,\n",
       "       20200217., 20200218., 20200219., 20200220., 20200221., 20200222.,\n",
       "       20200224., 20200225., 20200226., 20200227., 20200228., 20200229.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueCourierID\n",
    "uniqueDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-609b658a7a53>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-609b658a7a53>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    http://127.0.0.1:8080/confirmAddJob?rowID=7587\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# getRoutedGeocode(590)\n",
    "# getETAByID(458)\n",
    "# 590 690 765 458 455 756 727 758 644\n",
    "# dict_t = changeTime(758, \"15:30:00\", \"16:30:00\")\n",
    "# confirmChangeTime(590)\n",
    "# changeJob('{\"Cstomer Name\":\"FG FAMILY GOLD\",\"Street\":\"NO.113, JLN KESUMA 4B \\\\/ 1\\\\nBDR TASIK KESUMA 40 SELANGOR\\\\nBERANANG\",\"zip\":\"43700\",\"City\":\"BERANANG\",\"Act Dt\":20200201,\"Act Base\":\"P\",\"Open\":\"9:00\",\"Closed\":\"12:00\",\"Prod Grp\":\"WPX\",\"Prod Code\":\"P\",\"Total Pcs\":2.0,\"Weight\":1.78}')\n",
    "# confirmAddJob(7588)\n",
    "\n",
    "# http://127.0.0.1:8080/confirmAddJob?rowID=7587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\"confirm with id 7587\"\\n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"Customer Name\":\"FG FAMILY GOLD\",\"Street\":\"NO.113, JLN KESUMA 4B \\\\/ 1\\\\nBDR TASIK KESUMA 40 SELANGOR\\\\nBERANANG\",\"zip\":\"43700\",\"City\":\"BERANANG\",\"Act Dt\":20200201,\"Act Base\":\"P\",\"Open\":\"9:00\",\"Closed\":\"12:00\",\"Prod Grp\":\"WPX\",\"Prod Code\":\"P\",\"Total Pcs\":2.0,\"Weight\":1.78}\n",
    "r = requests.post(\"http://127.0.0.1:8080/addJob?rowID=680\",json=json.dumps(data), headers=headers)\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"15:26:45\"'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(getETAByID(690))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger no cloud geocode . . .\n",
      "capacity : [12]\n",
      "14\n",
      "created json file\n",
      "created csv file . . ..\n",
      "create new optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lun\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:743: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created updated response json file\n",
      "trigger no cloud geocode . . .\n",
      "capacity : [13]\n",
      "14\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created json file\n",
      "created csv file . . ..\n",
      "update optimal route csv\n",
      "created updated response json file\n"
     ]
    }
   ],
   "source": [
    "session = \"a\"\n",
    "test_dict_t = tryGotUnassignedInResponse2(date,session,street)\n",
    "session = \"m\"\n",
    "test_dict_t = tryGotUnassignedInResponse2(date,session,street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(routesIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCSVToGStorage(awb_booking):\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucketName)\n",
    "    fullDataFrame = pd.read_csv(gStorage)\n",
    "    fullDataFrame[\"awb_booking\"] = fullDataFrame['awb_booking'].astype(str)\n",
    "    rowToUpdate = fullDataFrame.loc[(fullDataFrame[\"awb_booking\"] == awb_booking )]\n",
    "    if( len(rowToUpdate.index) != 0):\n",
    "        session = awb_booking.split(\"_\")[0]\n",
    "        session = \"m\"\n",
    "        dict_t = getResponseFileAsDict()\n",
    "\n",
    "        ID = rowToUpdate.iloc[0][\"id\"]\n",
    "        route, indexStep, vehicleID = getRouteDetailWithID(ID)\n",
    "        if(route != [] or indexStep != [] or vehicleID != []):\n",
    "            print(rowToUpdate.index[0])\n",
    "            arrivalTime = route[\"steps\"][indexStep][\"arrival\"]\n",
    "\n",
    "            vehicleInformation = fullDataFrame.loc[(fullDataFrame [\"id\"] == vehicleID )]\n",
    "            if(len(vehicleInformation.index) != 0):\n",
    "                vehicleInformation = vehicleInformation.reset_index(drop = True)\n",
    "                if(len(rowToUpdate.index) != 0):\n",
    "                    fullDataFrame.at[rowToUpdate.index[0].astype(int), \"Courier Type\"] = vehicleInformation.iloc[0][\"Courier Type\"]\n",
    "                    fullDataFrame.at[rowToUpdate.index[0], \"PUD Svc Area\"] = vehicleInformation.iloc[0][\"PUD Svc Area\"]\n",
    "                    fullDataFrame.at[rowToUpdate.index[0], \"PUD Fac\"] = vehicleInformation.iloc[0][\"PUD Fac\"]\n",
    "                    fullDataFrame.at[rowToUpdate.index[0], \"PUD Rte\"] = vehicleInformation.iloc[0][\"PUD Rte\"]\n",
    "                    fullDataFrame.at[rowToUpdate.index[0], \"PUD Cycle\"] = vehicleInformation.iloc[0][\"PUD Cycle\"]\n",
    "                    fullDataFrame.at[rowToUpdate.index[0], \"Courier id\"] = vehicleInformation.iloc[0][\"Courier id\"]\n",
    "                    fullDataFrame.at[rowToUpdate.index[0], \"Act Tm\"] = getTime24hour(arrivalTime)\n",
    "                    string = fullDataFrame.to_csv(None, index=False)\n",
    "                    blob = bucket.blob(\"3.csv\")\n",
    "                    blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "                    return True\n",
    "                else:\n",
    "                    return {\"Error\" : \"vehicleID not found in db\"}\n",
    "            else:\n",
    "                return {\"Error\" : \"ID not found in db\"}\n",
    "        else:\n",
    "            return {\"Error\" : \"ID not found in route\"}\n",
    "    else:\n",
    "#         print(type(awb_booking))\n",
    "#         print(type(fullDataFrame[\"awb_booking\"][0]))\n",
    "#         print(rowToUpdate)\n",
    "        dbAwb = fullDataFrame.iloc[447][\"awb_booking\"]\n",
    "        return {\"Error\" : \"awb_booking not found in db.\"}\n",
    "\n",
    "testing = updateCSVToGStorage( abc[\"extra\"][\"awb_booking\"] )\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getRouteDetailWithID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1fc2144d8b5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexStep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvehicleID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetRouteDetailWithID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m448\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(response[\"routes\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getRouteDetailWithID' is not defined"
     ]
    }
   ],
   "source": [
    "route, indexStep, vehicleID = getRouteDetailWithID(448)\n",
    "\n",
    "response = abc\n",
    "# print(response[\"routes\"])\n",
    "\n",
    "#first row\n",
    "# vehicleInformation = fullDataFrame.loc[(fullDataFrame [\"id\"] == vehicleID )]\n",
    "# stepsInformation = fullDataFrmae.iloc(fullDataFrame[\"id\"] == 1)\n",
    "\n",
    "# print(route[\"steps\"])\n",
    "\n",
    "\n",
    "ids = []\n",
    "ids.append(vehicleID)\n",
    "for indexStep, step in enumerate( routes[\"steps\"], start = 1):\n",
    "    if(step[\"type\"] == \"job\"):\n",
    "        ids.append(step[\"job\"])\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[101.9381, 2.7297],\n",
       "  [101.942542, 2.7251453999999997],\n",
       "  [101.9552125, 2.723318],\n",
       "  [101.9536736, 2.6960765],\n",
       "  [101.9300755, 2.6957107999999996],\n",
       "  [101.9235314, 2.7024502],\n",
       "  [101.916898, 2.704746],\n",
       "  [101.9166755, 2.7047494],\n",
       "  [101.9166878, 2.7047096],\n",
       "  [101.9167236, 2.7047272],\n",
       "  [101.9167518, 2.7045911],\n",
       "  [101.9166245, 2.7047882999999997],\n",
       "  [101.9164988, 2.7048625],\n",
       "  [101.9164423, 2.7047654],\n",
       "  [101.916676, 2.7048283],\n",
       "  [101.9166613, 2.7048186000000003],\n",
       "  [101.9167006, 2.7048400000000004],\n",
       "  [101.9159438, 2.7010402],\n",
       "  [101.9175238, 2.6953908],\n",
       "  [101.9236249, 2.688915],\n",
       "  [101.9266453, 2.6848554],\n",
       "  [101.8980233, 2.6777029],\n",
       "  [101.9085892, 2.6872418999999996],\n",
       "  [101.9111368, 2.691144],\n",
       "  [101.9107812, 2.6940046000000004],\n",
       "  [101.9123992, 2.7015334],\n",
       "  [101.9112658, 2.7028797000000004],\n",
       "  [101.9390577, 2.7259512000000004],\n",
       "  [101.938135, 2.7284237],\n",
       "  [101.9381, 2.7297]],\n",
       " [101.9167518, 2.7045911],\n",
       " 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readed[\"routes\"]\n",
    "\n",
    "# readed[\"routes\"][\"steps\"]\n",
    "\n",
    "\n",
    "\n",
    "toPrint = getRouteDetail(500)\n",
    "\n",
    "toPrint\n",
    "# readed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_t = {\"1\" : \"ASDas\", \"2\" : \"adsdsadas\"}\n",
    "dict_t[\"2\"]\n",
    "\n",
    "if(dict_t[\"1\"] != \"ASDas\" and dict_t[\"3\"] == \"asdas\"):\n",
    "    print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lun\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "from flask import Flask, render_template\n",
    "\n",
    "# [START gae_python37_datastore_store_and_fetch_times]\n",
    "\n",
    "\n",
    "# [END gae_python37_datastore_store_and_fetch_times]\n",
    "app = Flask(__name__)\n",
    "\n",
    "# morningData = tryGotUnassignedInResponse2(date,session,street)\n",
    "\n",
    "\n",
    "# [START gae_python37_datastore_render_times]\n",
    "@app.route('/')\n",
    "def start():\n",
    "    # morningData = tryGotUnassignedInResponse(date,session,street)\n",
    "    print(\"start\")\n",
    "    return \"Hello\"\n",
    "# def root():\n",
    "\n",
    "@app.route('/try')\n",
    "def tryReturn():\n",
    "    # date = \"20200204\"\n",
    "    # session = \"m\"\n",
    "    # street = \"Jalan Rumbia, Kampung Seberang Paya, 11900 Bayan Lepas, Pulau Pinang\"\n",
    "# example\n",
    "# http://127.0.0.1:8080/try?date=20200204&session=m&street=Bj%20Court%20Condominium,%20Kampung%20Seberang%20Paya,%2011900%20Bayan%20Lepas,%20Pulau%20Pinang\n",
    "    from flask import request\n",
    "    date  = request.args.get('date')\n",
    "    session = request.args.get('session')\n",
    "    street = request.args.get('street')\n",
    "\n",
    "    # street = \"Bj Court Condominium, Kampung Seberang Paya, 11900 Bayan Lepas, Pulau Pinang\"\n",
    "    morningData = tryGotUnassignedInResponse2(date,session,street)\n",
    "    return morningData\n",
    "    # print(type(date))\n",
    "    # return street\n",
    "\n",
    "# [END gae_python37_datastore_render_times]\n",
    "\n",
    "\n",
    "@app.route('/openFile')\n",
    "def openFile():\n",
    "    from flask import Flask\n",
    "    from io import StringIO\n",
    "    from flask import jsonify\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket('real-bucket-dhl')\n",
    "    \n",
    "    blob = bucket.get_blob('3.csv')\n",
    "    your_file_contents = blob.download_as_string()\n",
    "\n",
    "    # df = pd.read_csv(StringIO(your_file_contents))\n",
    "    df = pd.read_csv('gs://real-bucket-dhl/3.csv')\n",
    "\n",
    "    # fullDataFrame = pd.read_csv(blob)\n",
    "    # return your_file_contents\n",
    "    # print(df.iloc[0][\"Courier id\"])\n",
    "\n",
    "    return jsonify(df.iloc[0][\"Courier id\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/uploadfile')\n",
    "def upload_blob():\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(\"real-bucket-dhl\")\n",
    "    \n",
    "    # fullDataFrame = pd.read_csv(csvPath)\n",
    "    df = pd.read_csv('gs://real-bucket-dhl/3.csv')\n",
    "    string = df.to_csv(None, index=False)\n",
    "\n",
    "    blob = bucket.blob(\"3.csv\")\n",
    "\n",
    "    blob.upload_from_string(string, \"application/vnd.ms-excel\")\n",
    "\n",
    "@app.route('/test')\n",
    "def another_function():\n",
    "\n",
    "    from flask import request\n",
    "    a  = request.args.get('first')\n",
    "    b = request.args.get('second')\n",
    "    return a + b\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # This is used when running locally only. When deploying to Google App\n",
    "    # Engine, a webserver process such as Gunicorn will serve the app. This\n",
    "    # can be configured by adding an `entrypoint` to app.yaml.\n",
    "\n",
    "    # Flask's development server will automatically serve static files in\n",
    "    # the \"static\" directory. See:\n",
    "    # http://flask.pocoo.org/docs/1.0/quickstart/#static-files. Once deployed,\n",
    "    # App Engine itself will serve those files as configured in app.yaml.\n",
    "    app.run(host='127.0.0.1', port=8080, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
